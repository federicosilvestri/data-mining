{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DM - Data preparation [TASK 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN Only with COLAB\n",
    "\n",
    "This cell will setup notebook for running on Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://FedericoSilvestri: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@github.com/federicosilvestri/data-mining.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4369/2227366743.py:10: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "import logging as lg\n",
    "\n",
    "root = lg.getLogger()\n",
    "root.setLevel(lg.INFO)\n",
    "\n",
    "handler = lg.StreamHandler(sys.stdout)\n",
    "handler.setLevel(lg.DEBUG)\n",
    "formatter = lg.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Fetching the dataset using our native python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load the CSV\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweets_cleaned.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m users \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musers_cleaned.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, lineseparator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1765\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     (\n\u001b[1;32m   1769\u001b[0m         index,\n\u001b[1;32m   1770\u001b[0m         columns,\n\u001b[1;32m   1771\u001b[0m         col_dict,\n\u001b[0;32m-> 1772\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py:243\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 243\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Load the CSV\n",
    "#\n",
    "tweets = pd.read_csv('dataset_cleaned/tweets_cleaned.csv', lineseparator='\\n')\n",
    "users = pd.read_csv('dataset_cleaned/users_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many tweets were published by the user?\n",
    "- How many tweets are published by the user in a given period of time?\n",
    "- Total number of tweets\n",
    "- Total number of likes and comments\n",
    "- Ratio between the number of tweets and the number of likes\n",
    "- Entropy of the user\n",
    "- Average length of the tweets per user\n",
    "- Average number of special characters in the tweets per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "column_name = 'tweets_num'\n",
    "tweets_grouped_by_users = tweets.groupby(['user_id']).size()\n",
    "users[column_name] = tweets_grouped_by_users\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_greater_2020 = tweets[tweets['created_at'] >= pd.Timestamp('2020-01-01')]\n",
    "tweets_filtered_2020 = tweets_greater_2020[tweets['created_at'] < pd.Timestamp('2021-01-01')]\n",
    "tweets_grouped_2020 = tweets_filtered_2020.groupby(['user_id']).size()\n",
    "\n",
    "column_name = 'tweets_2020_num'\n",
    "users[column_name] = tweets_grouped_2020\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'tweets_total_num'\n",
    "users[column_name] = users['statuses_count'] + users['tweets_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'likes_num'\n",
    "tweets_grouped_likes = tweets.rename(columns={'favorite_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_likes, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'comments_num'\n",
    "tweets_grouped_comments = tweets.rename(columns={'reply_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'ratio_tweets_likes'\n",
    "users[column_name] = users['tweets_total_num'] / users['likes_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'entropy'\n",
    "avg_tweets_total_num = users['tweets_total_num'] / users['tweets_total_num'].sum()\n",
    "users[column_name] = - (avg_tweets_total_num * np.log(avg_tweets_total_num))\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_total_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(lambda t: len(t))\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_special_chars_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "\n",
    "def count_special_chars(text):\n",
    "    count = 0\n",
    "    for ch in text:\n",
    "        if not ch.isalpha() and not ch.isdigit():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(count_special_chars)\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the team has to explore the new features for a statistical analysis (distributions, outliers, visualizations, correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_num'],\n",
    "        'title': 'Tweets num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_2020_num'],\n",
    "        'title': 'Tweets 2020 num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_total_num'],\n",
    "        'title': 'Tweets total num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['likes_num'],\n",
    "        'title': 'Likes num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['comments_num'],\n",
    "        'title': 'Comments num'\n",
    "    },\n",
    "    #{ # TODO GERE: inf values, understand how plot it\n",
    "    #    'type': 'hist',\n",
    "    #    'column': users['ratio_tweets_likes'],\n",
    "    #    'title': 'Ratio tweets likes'\n",
    "    #},\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['entropy'],\n",
    "        'title': 'Entropy'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_total_length'],\n",
    "        'title': 'Texts total length'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_special_chars_length'],\n",
    "        'title': 'Texts special chars length'\n",
    "    },\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_tweets_newfeatures_show():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_2020_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_total_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['likes_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['comments_num']\n",
    "        },\n",
    "        #{\n",
    "        #    'type': 'boxplot',\n",
    "        #    'df': users,\n",
    "        #    'columns': ['ratio_tweets_likes']\n",
    "        #},\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['entropy']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_total_length']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_special_chars_length']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)\n",
    "\n",
    "boxplot_tweets_newfeatures_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DM - Data preparation [TASK 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN Only with COLAB\n",
    "\n",
    "This cell will setup notebook for running on Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://FedericoSilvestri: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@github.com/federicosilvestri/data-mining.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4369/2227366743.py:10: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "import logging as lg\n",
    "\n",
    "root = lg.getLogger()\n",
    "root.setLevel(lg.INFO)\n",
    "\n",
    "handler = lg.StreamHandler(sys.stdout)\n",
    "handler.setLevel(lg.DEBUG)\n",
    "formatter = lg.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Fetching the dataset using our native python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load the CSV\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweets_cleaned.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m users \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musers_cleaned.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, lineseparator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1765\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     (\n\u001b[1;32m   1769\u001b[0m         index,\n\u001b[1;32m   1770\u001b[0m         columns,\n\u001b[1;32m   1771\u001b[0m         col_dict,\n\u001b[0;32m-> 1772\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py:243\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 243\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Load the CSV\n",
    "#\n",
    "tweets = pd.read_csv('dataset_cleaned/tweets_cleaned.csv', lineseparator='\\n')\n",
    "users = pd.read_csv('dataset_cleaned/users_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many tweets were published by the user?\n",
    "- How many tweets are published by the user in a given period of time?\n",
    "- Total number of tweets\n",
    "- Total number of likes and comments\n",
    "- Ratio between the number of tweets and the number of likes\n",
    "- Entropy of the user\n",
    "- Average length of the tweets per user\n",
    "- Average number of special characters in the tweets per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "column_name = 'tweets_num'\n",
    "tweets_grouped_by_users = tweets.groupby(['user_id']).size()\n",
    "users[column_name] = tweets_grouped_by_users\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_greater_2020 = tweets[tweets['created_at'] >= pd.Timestamp('2020-01-01')]\n",
    "tweets_filtered_2020 = tweets_greater_2020[tweets['created_at'] < pd.Timestamp('2021-01-01')]\n",
    "tweets_grouped_2020 = tweets_filtered_2020.groupby(['user_id']).size()\n",
    "\n",
    "column_name = 'tweets_2020_num'\n",
    "users[column_name] = tweets_grouped_2020\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'tweets_total_num'\n",
    "users[column_name] = users['statuses_count'] + users['tweets_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'likes_num'\n",
    "tweets_grouped_likes = tweets.rename(columns={'favorite_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_likes, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'comments_num'\n",
    "tweets_grouped_comments = tweets.rename(columns={'reply_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'ratio_tweets_likes'\n",
    "users[column_name] = users['tweets_total_num'] / users['likes_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'entropy'\n",
    "avg_tweets_total_num = users['tweets_total_num'] / users['tweets_total_num'].sum()\n",
    "users[column_name] = - (avg_tweets_total_num * np.log(avg_tweets_total_num))\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_total_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(lambda t: len(t))\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_special_chars_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "\n",
    "def count_special_chars(text):\n",
    "    count = 0\n",
    "    for ch in text:\n",
    "        if not ch.isalpha() and not ch.isdigit():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(count_special_chars)\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the team has to explore the new features for a statistical analysis (distributions, outliers, visualizations, correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_num'],\n",
    "        'title': 'Tweets num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_2020_num'],\n",
    "        'title': 'Tweets 2020 num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_total_num'],\n",
    "        'title': 'Tweets total num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['likes_num'],\n",
    "        'title': 'Likes num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['comments_num'],\n",
    "        'title': 'Comments num'\n",
    "    },\n",
    "    #{ # TODO GERE: inf values, understand how plot it\n",
    "    #    'type': 'hist',\n",
    "    #    'column': users['ratio_tweets_likes'],\n",
    "    #    'title': 'Ratio tweets likes'\n",
    "    #},\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['entropy'],\n",
    "        'title': 'Entropy'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_total_length'],\n",
    "        'title': 'Texts total length'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_special_chars_length'],\n",
    "        'title': 'Texts special chars length'\n",
    "    },\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_tweets_newfeatures_show():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_2020_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_total_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['likes_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['comments_num']\n",
    "        },\n",
    "        #{\n",
    "        #    'type': 'boxplot',\n",
    "        #    'df': users,\n",
    "        #    'columns': ['ratio_tweets_likes']\n",
    "        #},\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['entropy']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_total_length']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_special_chars_length']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)\n",
    "\n",
    "boxplot_tweets_newfeatures_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
