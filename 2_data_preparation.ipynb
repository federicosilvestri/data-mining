{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DM - Data preparation [TASK 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN Only with COLAB\n",
    "\n",
    "This cell will setup notebook for running on Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://FedericoSilvestri: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@github.com/federicosilvestri/data-mining.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_538121/2243393596.py:10: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "from utils import fetch_preprocessed_dataset, store_preprocessed_dataset\n",
    "\n",
    "import sys\n",
    "import logging as lg\n",
    "\n",
    "root = lg.getLogger()\n",
    "root.setLevel(lg.INFO)\n",
    "\n",
    "handler = lg.StreamHandler(sys.stdout)\n",
    "handler.setLevel(lg.DEBUG)\n",
    "formatter = lg.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Fetching the dataset using our native python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Load the CSV\n",
    "#\n",
    "dataset = fetch_preprocessed_dataset(step_name=\"preprocess\")\n",
    "tweets = dataset['tweets.csv']\n",
    "users = dataset['users.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many tweets were published by the user?\n",
    "- How many tweets are published by the user in a given period of time?\n",
    "- Total number of tweets\n",
    "- Total number of likes and comments\n",
    "- Ratio between the number of tweets and the number of likes\n",
    "- Entropy of the user\n",
    "- Average length of the tweets per user\n",
    "- Average number of special characters in the tweets per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>bot</th>\n",
       "      <th>created_at</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>tweets_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2353593986</td>\n",
       "      <td>Lamonica Raborn</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-02-22 18:00:42</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2358850842</td>\n",
       "      <td>Lourie Botton</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-26 03:02:32</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>137959629</td>\n",
       "      <td>Dadan Syarifudin</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-04-30 07:09:56</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>466124818</td>\n",
       "      <td>Carletto Focia</td>\n",
       "      <td>it</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-18 02:49:18</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2571493866</td>\n",
       "      <td>MBK Ebook</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-06-18 19:30:21</td>\n",
       "      <td>7085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11503</th>\n",
       "      <td>11503</td>\n",
       "      <td>2911861962</td>\n",
       "      <td>Madrid Lae Maika .</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-11-29 13:16:02</td>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11504</th>\n",
       "      <td>11504</td>\n",
       "      <td>1378532629</td>\n",
       "      <td>Clau Sato</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-04-27 03:01:58</td>\n",
       "      <td>3024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11505</th>\n",
       "      <td>11505</td>\n",
       "      <td>126984069</td>\n",
       "      <td>ALMA LETICIA NUÑO</td>\n",
       "      <td>es</td>\n",
       "      <td>False</td>\n",
       "      <td>2015-03-29 17:01:24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11506</th>\n",
       "      <td>11506</td>\n",
       "      <td>2383025796</td>\n",
       "      <td>Minnie Guadagno</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-03-13 02:44:13</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11507</th>\n",
       "      <td>11507</td>\n",
       "      <td>933183398</td>\n",
       "      <td>Corvanna</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-11-09 23:24:16</td>\n",
       "      <td>5279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11508 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          id                name lang    bot  \\\n",
       "0               0  2353593986     Lamonica Raborn   en   True   \n",
       "1               1  2358850842       Lourie Botton   en  False   \n",
       "2               2   137959629    Dadan Syarifudin   en   True   \n",
       "3               3   466124818      Carletto Focia   it   True   \n",
       "4               4  2571493866           MBK Ebook   en  False   \n",
       "...           ...         ...                 ...  ...    ...   \n",
       "11503       11503  2911861962  Madrid Lae Maika .   en  False   \n",
       "11504       11504  1378532629           Clau Sato   en  False   \n",
       "11505       11505   126984069  ALMA LETICIA NUÑO    es  False   \n",
       "11506       11506  2383025796     Minnie Guadagno   en   True   \n",
       "11507       11507   933183398           Corvanna    en  False   \n",
       "\n",
       "                created_at  statuses_count  tweets_num  \n",
       "0      2019-02-22 18:00:42              76           0  \n",
       "1      2019-02-26 03:02:32              54           0  \n",
       "2      2015-04-30 07:09:56               3           0  \n",
       "3      2017-01-18 02:49:18              50           1  \n",
       "4      2019-06-18 19:30:21            7085           0  \n",
       "...                    ...             ...         ...  \n",
       "11503  2019-11-29 13:16:02            1126           0  \n",
       "11504  2018-04-27 03:01:58            3024           0  \n",
       "11505  2015-03-29 17:01:24               6           0  \n",
       "11506  2019-03-13 02:44:13              42           0  \n",
       "11507  2017-11-09 23:24:16            5279           0  \n",
       "\n",
       "[11508 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = 'tweets_num'\n",
    "tweets_grouped_by_users = tweets.groupby(['user_id']).size()\n",
    "users[column_name] = tweets_grouped_by_users\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_filtered_2020' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(datetime) \u001b[38;5;241m<\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m tweets_greater_2020 \u001b[38;5;241m=\u001b[39m tweets[tweets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(filter_datetime_2020)]\n\u001b[0;32m----> 5\u001b[0m tweets_grouped_2020 \u001b[38;5;241m=\u001b[39m \u001b[43mtweets_filtered_2020\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m      7\u001b[0m column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweets_2020_num\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m users[column_name] \u001b[38;5;241m=\u001b[39m tweets_grouped_2020\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets_filtered_2020' is not defined"
     ]
    }
   ],
   "source": [
    "def filter_datetime_2020(datetime):\n",
    "    return pd.Timestamp('2020-01-01') <= pd.Timestamp(datetime) < pd.Timestamp('2021-01-01')\n",
    "\n",
    "tweets_greater_2020 = tweets[tweets['created_at'].map(filter_datetime_2020)]\n",
    "tweets_grouped_2020 = tweets_filtered_2020.groupby(['user_id']).size()\n",
    "\n",
    "column_name = 'tweets_2020_num'\n",
    "users[column_name] = tweets_grouped_2020\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'tweets_total_num'\n",
    "users[column_name] = users['statuses_count'] + users['tweets_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'likes_num'\n",
    "tweets_grouped_likes = tweets.rename(columns={'favorite_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_likes, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'comments_num'\n",
    "tweets_grouped_comments = tweets.rename(columns={'reply_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'ratio_tweets_likes'\n",
    "users[column_name] = users['tweets_total_num'] / users['likes_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'entropy'\n",
    "avg_tweets_total_num = users['tweets_total_num'] / users['tweets_total_num'].sum()\n",
    "users[column_name] = - (avg_tweets_total_num * np.log(avg_tweets_total_num))\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_total_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(lambda t: len(t))\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_special_chars_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "\n",
    "def count_special_chars(text):\n",
    "    count = 0\n",
    "    for ch in text:\n",
    "        if not ch.isalpha() and not ch.isdigit():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(count_special_chars)\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the team has to explore the new features for a statistical analysis (distributions, outliers, visualizations, correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_num'],\n",
    "        'title': 'Tweets num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_2020_num'],\n",
    "        'title': 'Tweets 2020 num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_total_num'],\n",
    "        'title': 'Tweets total num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['likes_num'],\n",
    "        'title': 'Likes num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['comments_num'],\n",
    "        'title': 'Comments num'\n",
    "    },\n",
    "    #{ # TODO GERE: inf values, understand how plot it\n",
    "    #    'type': 'hist',\n",
    "    #    'column': users['ratio_tweets_likes'],\n",
    "    #    'title': 'Ratio tweets likes'\n",
    "    #},\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['entropy'],\n",
    "        'title': 'Entropy'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_total_length'],\n",
    "        'title': 'Texts total length'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_special_chars_length'],\n",
    "        'title': 'Texts special chars length'\n",
    "    },\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_tweets_newfeatures_show():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_2020_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_total_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['likes_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['comments_num']\n",
    "        },\n",
    "        #{\n",
    "        #    'type': 'boxplot',\n",
    "        #    'df': users,\n",
    "        #    'columns': ['ratio_tweets_likes']\n",
    "        #},\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['entropy']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_total_length']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_special_chars_length']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)\n",
    "\n",
    "boxplot_tweets_newfeatures_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DM - Data preparation [TASK 1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN Only with COLAB\n",
    "\n",
    "This cell will setup notebook for running on Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://FedericoSilvestri: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@github.com/federicosilvestri/data-mining.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4369/2227366743.py:10: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "import logging as lg\n",
    "\n",
    "root = lg.getLogger()\n",
    "root.setLevel(lg.INFO)\n",
    "\n",
    "handler = lg.StreamHandler(sys.stdout)\n",
    "handler.setLevel(lg.DEBUG)\n",
    "formatter = lg.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Fetching the dataset using our native python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load the CSV\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweets_cleaned.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m users \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musers_cleaned.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, lineseparator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1765\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     (\n\u001b[1;32m   1769\u001b[0m         index,\n\u001b[1;32m   1770\u001b[0m         columns,\n\u001b[1;32m   1771\u001b[0m         col_dict,\n\u001b[0;32m-> 1772\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py:243\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 243\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Load the CSV\n",
    "#\n",
    "tweets = pd.read_csv('dataset_cleaned/tweets_cleaned.csv', lineseparator='\\n')\n",
    "users = pd.read_csv('dataset_cleaned/users_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many tweets were published by the user?\n",
    "- How many tweets are published by the user in a given period of time?\n",
    "- Total number of tweets\n",
    "- Total number of likes and comments\n",
    "- Ratio between the number of tweets and the number of likes\n",
    "- Entropy of the user\n",
    "- Average length of the tweets per user\n",
    "- Average number of special characters in the tweets per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "column_name = 'tweets_num'\n",
    "tweets_grouped_by_users = tweets.groupby(['user_id']).size()\n",
    "users[column_name] = tweets_grouped_by_users\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_greater_2020 = tweets[tweets['created_at'] >= pd.Timestamp('2020-01-01')]\n",
    "tweets_filtered_2020 = tweets_greater_2020[tweets['created_at'] < pd.Timestamp('2021-01-01')]\n",
    "tweets_grouped_2020 = tweets_filtered_2020.groupby(['user_id']).size()\n",
    "\n",
    "column_name = 'tweets_2020_num'\n",
    "users[column_name] = tweets_grouped_2020\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'tweets_total_num'\n",
    "users[column_name] = users['statuses_count'] + users['tweets_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'likes_num'\n",
    "tweets_grouped_likes = tweets.rename(columns={'favorite_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_likes, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'comments_num'\n",
    "tweets_grouped_comments = tweets.rename(columns={'reply_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'ratio_tweets_likes'\n",
    "users[column_name] = users['tweets_total_num'] / users['likes_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'entropy'\n",
    "avg_tweets_total_num = users['tweets_total_num'] / users['tweets_total_num'].sum()\n",
    "users[column_name] = - (avg_tweets_total_num * np.log(avg_tweets_total_num))\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_total_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(lambda t: len(t))\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_special_chars_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "\n",
    "def count_special_chars(text):\n",
    "    count = 0\n",
    "    for ch in text:\n",
    "        if not ch.isalpha() and not ch.isdigit():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(count_special_chars)\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the team has to explore the new features for a statistical analysis (distributions, outliers, visualizations, correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_num'],\n",
    "        'title': 'Tweets num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_2020_num'],\n",
    "        'title': 'Tweets 2020 num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_total_num'],\n",
    "        'title': 'Tweets total num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['likes_num'],\n",
    "        'title': 'Likes num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['comments_num'],\n",
    "        'title': 'Comments num'\n",
    "    },\n",
    "    #{ # TODO GERE: inf values, understand how plot it\n",
    "    #    'type': 'hist',\n",
    "    #    'column': users['ratio_tweets_likes'],\n",
    "    #    'title': 'Ratio tweets likes'\n",
    "    #},\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['entropy'],\n",
    "        'title': 'Entropy'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_total_length'],\n",
    "        'title': 'Texts total length'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_special_chars_length'],\n",
    "        'title': 'Texts special chars length'\n",
    "    },\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_tweets_newfeatures_show():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_2020_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_total_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['likes_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['comments_num']\n",
    "        },\n",
    "        #{\n",
    "        #    'type': 'boxplot',\n",
    "        #    'df': users,\n",
    "        #    'columns': ['ratio_tweets_likes']\n",
    "        #},\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['entropy']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_total_length']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_special_chars_length']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)\n",
    "\n",
    "boxplot_tweets_newfeatures_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
