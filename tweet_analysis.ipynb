{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN Only with COLAB\n",
    "\n",
    "This cell will setup notebook for running on Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://FedericoSilvestri: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@github.com/federicosilvestri/data-mining.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2676/2227366743.py:10: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "import logging as lg\n",
    "\n",
    "root = lg.getLogger()\n",
    "root.setLevel(lg.INFO)\n",
    "\n",
    "handler = lg.StreamHandler(sys.stdout)\n",
    "handler.setLevel(lg.DEBUG)\n",
    "formatter = lg.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Fetching the dataset using our native python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-29 17:30:54,149 - root - INFO - Pandas reading dataset tweets.csv...\n",
      "2022-10-29 17:30:54,149 - root - INFO - Pandas reading dataset tweets.csv...\n",
      "2022-10-29 17:31:11,703 - root - INFO - Pandas reading dataset users.csv...\n",
      "2022-10-29 17:31:11,703 - root - INFO - Pandas reading dataset users.csv...\n"
     ]
    }
   ],
   "source": [
    "from utils import fetch_dataset\n",
    "\n",
    "dataset = fetch_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.1\n",
    "\n",
    "Exploring the dataset with analytical tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users\n",
    "\n",
    "Show `users.csv` information: types of data and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11508 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              11508 non-null  int64  \n",
      " 1   name            11507 non-null  object \n",
      " 2   lang            11508 non-null  object \n",
      " 3   bot             11508 non-null  int64  \n",
      " 4   created_at      11508 non-null  object \n",
      " 5   statuses_count  11109 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 539.6+ KB\n"
     ]
    }
   ],
   "source": [
    "users = dataset['users.csv'].copy() # make a copy\n",
    "\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en                    9970\n",
       "it                     906\n",
       "es                     319\n",
       "pt                      65\n",
       "en-gb                   50\n",
       "ru                      42\n",
       "fr                      36\n",
       "ja                      33\n",
       "zh-tw                   17\n",
       "tr                      14\n",
       "id                      12\n",
       "ko                       9\n",
       "de                       8\n",
       "nl                       6\n",
       "en-GB                    4\n",
       "ar                       3\n",
       "zh-TW                    3\n",
       "da                       2\n",
       "Select Language...       2\n",
       "en-AU                    1\n",
       "zh-cn                    1\n",
       "pl                       1\n",
       "el                       1\n",
       "fil                      1\n",
       "sv                       1\n",
       "xx-lc                    1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display lang values\n",
    "users['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have:\n",
    "\n",
    "1. `xx-lc`\n",
    "2. `Select Language...`\n",
    "\n",
    "That are not a valid language.\n",
    "We have decided to use iso639-1 Python library to detect valid languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6116\n",
       "0    5392\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display BOT values\n",
    "# 0 -> it's a human!\n",
    "# 1 -> it's a bot!\n",
    "users['bot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have clean data for `bot` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets\n",
    "\n",
    "Show `tweets.csv information: types of data and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   id              object\n",
      " 1   user_id         object\n",
      " 2   retweet_count   object\n",
      " 3   reply_count     object\n",
      " 4   favorite_count  object\n",
      " 5   num_hashtags    object\n",
      " 6   num_urls        object\n",
      " 7   num_mentions    object\n",
      " 8   created_at      object\n",
      " 9   text            object\n",
      "dtypes: object(10)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "tweets = dataset['tweets.csv'].copy()\n",
    "\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding\n",
    "\n",
    "In these cells we are going to understand and clean the data of two datasets.\n",
    "The analysis performs:\n",
    "\n",
    "1. Replacement of null values with median if type is numerical, mode if type is categorical and **outlier** timestamp value if type is datetime.\n",
    "2. Deletion of rows that has a ratio between valid values and invalid values `< k` where `k` is a param with default value 60%.\n",
    "3. Understand and replace categorical value based on their domain. For example, the language column contains invalid language codes, and we replace them with the mode value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definition for outlier values\n",
    "min_date = pd.Timestamp('2006-03-21') # the date when Twitter has started the activity.\n",
    "max_date = pd.Timestamp('2022-09-28') # the date when dataset has been collected.\n",
    "\n",
    "# OUTLIER constants\n",
    "OUTLIER_TIMESTAMP = pd.Timestamp('1800-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_invalid_rows(df, column_validators, ratio=0.6):\n",
    "    #\n",
    "    # This function is a generic function, that performs cleaning of rows that are invalid.\n",
    "    # We define row as invalid if the ratio between valid and invalid attributes \n",
    "    # is greater than `ratio` parameter.\n",
    "    # \n",
    "    # The validation of single attribute is entrusted to the combination of \n",
    "    # lambda function named `validator` and the fact that the attribute is nan.\n",
    "    #\n",
    "    n_null_items = int(len(column_validators) * ratio)\n",
    "    rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        count = 0\n",
    "        for head, validator in column_validators:\n",
    "            if row[head] == np.nan or (validator is not None and validator(row[head])):\n",
    "                count += 1\n",
    "        if count > n_null_items:\n",
    "            rows.append(i)\n",
    "    df.drop(df.index[rows], inplace=True)\n",
    "    return rows\n",
    "\n",
    "# Definition of generic lambda validator functions\n",
    "check_int = lambda label: not bool(re.search(r'^(\\d)+(\\.0+)?$', str(label))) # checks, using regex if attribute is integer\n",
    "check_positive_int = lambda label: check_int(label) or float(label) < 0 # checks if label is positive\n",
    "check_date = lambda label: pd.Timestamp(label) < min_date or pd.Timestamp(label) > max_date # checks timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-29 17:35:02,497 - root - INFO - Deleted rows: 0\n",
      "2022-10-29 17:35:02,497 - root - INFO - Deleted rows: 0\n"
     ]
    }
   ],
   "source": [
    "from langcodes import tag_is_valid # import the library for ISO639-1 codes\n",
    "\n",
    "# For each column define a validator.\n",
    "column_validators = [\n",
    "    ('id', check_int),\n",
    "    ('name', None),\n",
    "    ('lang', tag_is_valid),\n",
    "    ('bot', lambda label: label == '1' or label == '0'),\n",
    "    ('statuses_count', check_int),\n",
    "    ('created_at', check_date),\n",
    "]\n",
    "\n",
    "#\n",
    "# Execute the cleaning function.\n",
    "#\n",
    "deleted_rows = clean_invalid_rows(users, column_validators)\n",
    "lg.info(f\"Deleted rows: {len(deleted_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Replacement of invalid names\n",
    "#\n",
    "users['name'].replace(np.nan, '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6116\n",
       "0    5392\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Explore bot column\n",
    "#\n",
    "users['bot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all values of column bot are 0,1 so we can convert it into boolean field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting to bool\n",
    "users = users.astype({'bot': 'bool'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       9973\n",
       "it        906\n",
       "es        319\n",
       "pt         65\n",
       "en-gb      54\n",
       "ru         42\n",
       "fr         36\n",
       "ja         33\n",
       "zh-tw      20\n",
       "tr         14\n",
       "id         12\n",
       "ko          9\n",
       "de          8\n",
       "nl          6\n",
       "ar          3\n",
       "da          2\n",
       "en-au       1\n",
       "zh-cn       1\n",
       "pl          1\n",
       "el          1\n",
       "fil         1\n",
       "sv          1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Replacement of invalid languages\n",
    "#\n",
    "\n",
    "# first normalize to lower case all langs\n",
    "users['lang'] = users['lang'].str.lower()\n",
    "\n",
    "# calculate the mode for this categorical value\n",
    "user_lang_mode = users['lang'].mode()[0]\n",
    "\n",
    "# lambda function for substition\n",
    "lang_subst_lambda = lambda x: x if tag_is_valid(x) else user_lang_mode\n",
    "\n",
    "# execute substitution\n",
    "users['lang'].map(lang_subst_lambda).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define a constant that marks an attribute as an outlier.\n",
    "#\n",
    "\n",
    "def filter_datetime(df, att):\n",
    "    def parse_and_check_datetime(el):\n",
    "        try:\n",
    "            datetime = pd.Timestamp(el) # parse datetime as Timestamp\n",
    "            # checks validity\n",
    "            if datetime < min_date or datetime > max_date:\n",
    "                # is an outlier\n",
    "                return OUTLIER_TIMESTAMP\n",
    "            else:\n",
    "                # is not an outlier\n",
    "                return datetime\n",
    "        except ValueError:\n",
    "            # cannot parse as timestamp, it's an outlier\n",
    "            return OUTLIER_TIMESTAMP\n",
    "\n",
    "    df[att] = df[att].map(parse_and_check_datetime)\n",
    "\n",
    "    return df.astype({att: 'datetime64[ns]'})\n",
    "\n",
    "# Apply the filter to datetime column\n",
    "users = filter_datetime(users, 'created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Handling tyhe statuses_count column.\n",
    "#\n",
    "status_count_median = users['statuses_count'].median()\n",
    "\n",
    "# replace the null values with median\n",
    "users['statuses_count'].replace(np.nan, status_count_median, inplace=True)\n",
    "\n",
    "# Convert the column `status_count` to int64 type.\n",
    "users = users.astype({'statuses_count': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-29 17:35:10,224 - root - INFO - Starting removing duplicates\n",
      "2022-10-29 17:35:10,224 - root - INFO - Starting removing duplicates\n",
      "2022-10-29 17:35:10,232 - root - INFO - Number of duplicates = 0\n",
      "2022-10-29 17:35:10,232 - root - INFO - Number of duplicates = 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Removing duplicate records.\n",
    "#\n",
    "lg.info(\"Starting removing duplicates\")\n",
    "initial_size = len(users)\n",
    "users = users.drop_duplicates()\n",
    "lg.info(f\"Number of duplicates = {initial_size - len(users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11508 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id              11508 non-null  int64         \n",
      " 1   name            11508 non-null  object        \n",
      " 2   lang            11508 non-null  object        \n",
      " 3   bot             11508 non-null  bool          \n",
      " 4   created_at      11508 non-null  datetime64[ns]\n",
      " 5   statuses_count  11508 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 550.7+ KB\n"
     ]
    }
   ],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all the columns are now validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>bot</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11508</td>\n",
       "      <td>11508</td>\n",
       "      <td>11508</td>\n",
       "      <td>11508.000000</td>\n",
       "      <td>11508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11361</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sara</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>9970</td>\n",
       "      <td>6116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5681.686566</td>\n",
       "      <td>2017-10-03 21:23:16.013121280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012-01-24 01:57:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2017-01-18 09:50:16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2018-01-30 17:20:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2520.250000</td>\n",
       "      <td>2019-02-25 00:17:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399555.000000</td>\n",
       "      <td>2020-04-21 07:28:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18769.594489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   lang    bot  statuses_count                     created_at\n",
       "count   11508  11508  11508    11508.000000                          11508\n",
       "unique  11361     24      2             NaN                            NaN\n",
       "top      Sara     en   True             NaN                            NaN\n",
       "freq        7   9970   6116             NaN                            NaN\n",
       "mean      NaN    NaN    NaN     5681.686566  2017-10-03 21:23:16.013121280\n",
       "min       NaN    NaN    NaN        0.000000            2012-01-24 01:57:38\n",
       "25%       NaN    NaN    NaN       42.000000     2017-01-18 09:50:16.500000\n",
       "50%       NaN    NaN    NaN       68.000000            2018-01-30 17:20:36\n",
       "75%       NaN    NaN    NaN     2520.250000            2019-02-25 00:17:30\n",
       "max       NaN    NaN    NaN   399555.000000            2020-04-21 07:28:31\n",
       "std       NaN    NaN    NaN    18769.594489                            NaN"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Describe the pre-processed dataset with all columns.\n",
    "#\n",
    "users[['name', 'lang', 'bot', 'statuses_count', 'created_at']].describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-29 17:47:30,707 - root - INFO - Starting dataset cleaning with validators...\n",
      "2022-10-29 17:47:30,707 - root - INFO - Starting dataset cleaning with validators...\n",
      "2022-10-29 18:04:45,870 - root - INFO - Deleted rows 16490\n",
      "2022-10-29 18:04:45,870 - root - INFO - Deleted rows 16490\n"
     ]
    }
   ],
   "source": [
    "column_validators = [\n",
    "    ('id', check_positive_int),\n",
    "    ('user_id', check_positive_int),\n",
    "    ('retweet_count', check_positive_int),\n",
    "    ('reply_count', check_positive_int),\n",
    "    ('favorite_count', check_positive_int),\n",
    "    ('num_hashtags', check_positive_int),\n",
    "    ('num_urls', check_positive_int),\n",
    "    ('num_mentions', check_positive_int),\n",
    "    ('created_at', check_date),\n",
    "    ('text', None),\n",
    "]\n",
    "\n",
    "# clean the dataset using validators ratio function.\n",
    "lg.info(\"Starting dataset cleaning with validators...\")\n",
    "deleted_rows = clean_invalid_rows(tweets, column_validators)\n",
    "lg.info(f\"Deleted rows {len(deleted_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-29 18:22:14,004 - root - INFO - Deleted 12786198 rows with invalid user_id\n",
      "2022-10-29 18:22:14,004 - root - INFO - Deleted 12786198 rows with invalid user_id\n",
      "2022-10-29 18:22:14,011 - root - INFO - Dropped 3.260932230588592% of dataset\n",
      "2022-10-29 18:22:14,011 - root - INFO - Dropped 3.260932230588592% of dataset\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# cleaning the user id\n",
    "#\n",
    "to_delete = tweets['user_id'].map(check_int)\n",
    "tweets.drop(tweets[to_delete].index, inplace=True)\n",
    "lg.info(f\"Deleted {len(tweets) - to_delete.sum()} rows with invalid user_id\")\n",
    "lg.info(f\"Dropped {to_delete.sum() / len(tweets) * 100}% of dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1579535068565057"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "to_delete.sum() / len(tweets) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tweets = replace_with_median(tweets, 'retweet_count')\n",
    "tweets = replace_with_median(tweets, 'reply_count')\n",
    "tweets = replace_with_median(tweets, 'favorite_count')\n",
    "tweets = replace_with_median(tweets, 'num_hashtags')\n",
    "tweets = replace_with_median(tweets, 'num_urls')\n",
    "tweets = replace_with_median(tweets, 'num_mentions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets['text'].replace(np.nan, '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets = filter_datetime(tweets, 'created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f'start length: {len(tweets)}')\n",
    "tweets = tweets.drop_duplicates()\n",
    "print(f'end length: {len(tweets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def build_grid_plot(configs):\n",
    "    cols = 2 if len(configs) <= 4 else 3\n",
    "    rows = math.ceil(len(configs) / cols)\n",
    "    fig_dims = (rows, cols)\n",
    "    fig = plt.figure(figsize=(20, rows * 5))\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "    for i, config in enumerate(configs):\n",
    "        if i == len(configs) - 1 and len(configs) % cols == 1 and cols % 2 == 1:\n",
    "            plt.subplot2grid(fig_dims, (i // cols, cols // 2))\n",
    "        else:\n",
    "            plt.subplot2grid(fig_dims, (i // cols, i % cols))\n",
    "        if config['type'] == 'hist':\n",
    "            config['column'].hist(bins=int(math.log2(len(config['column'])) + 1))\n",
    "            plt.title(config['title'])\n",
    "        elif config['type'] == 'bar':\n",
    "            config['column'].value_counts().plot(kind='bar', title=config['title'])\n",
    "            if ('rotation' in config) and config['rotation']:\n",
    "                plt.xticks(rotation=0)\n",
    "        elif config['type'] == 'boxplot':\n",
    "            config['df'].boxplot(column=config['columns'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['retweet_count'],\n",
    "        'title': 'Retweet Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['reply_count'],\n",
    "        'title': 'Replay Counts',\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['favorite_count'],\n",
    "        'title': 'Favorite Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['num_hashtags'],\n",
    "        'title': 'Hashtag Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['num_urls'],\n",
    "        'title': 'Url Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['num_mentions'],\n",
    "        'title': 'Mentions Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['created_at'],\n",
    "        'title': 'Tweets Creation Date Distribution'\n",
    "    }\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['statuses_count'],\n",
    "        'title': 'Statues Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'bar',\n",
    "        'column': users['bot'].map(lambda v: 'Bot' if v else 'User'),\n",
    "        'title': 'Bot and User Counts',\n",
    "        'rotation': True\n",
    "    },\n",
    "    {\n",
    "        'type': 'bar',\n",
    "        'column': users['lang'],\n",
    "        'title': 'Languages Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['created_at'],\n",
    "        'title': 'User Creation Date Distribution'\n",
    "    }\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_outliers(df, column_name, threshold):\n",
    "    column = df[column_name]\n",
    "    to_replace = len(column[column > threshold])\n",
    "    perc_to_replace = round((to_replace / len(column) * 100), 2)\n",
    "    lg.info(f'{to_replace} ({perc_to_replace}) element replaced for column {column_name}')\n",
    "    column[column > threshold] = column.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def boxplot_tweets_show():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['retweet_count']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['reply_count']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['favorite_count']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_hashtags']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_urls']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_mentions']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "boxplot_tweets_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "replace_outliers(tweets, 'retweet_count', 6e5)\n",
    "replace_outliers(tweets, 'reply_count', 6e4)\n",
    "replace_outliers(tweets, 'favorite_count', 1.2e5)\n",
    "replace_outliers(tweets, 'num_hashtags', 1e4)\n",
    "replace_outliers(tweets, 'num_urls', 1e4)\n",
    "replace_outliers(tweets, 'num_mentions', 1e5)\n",
    "\n",
    "boxplot_tweets_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "tweets.plot.scatter(x='reply_count', y='favorite_count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● How many tweets were published by the user?\n",
    "● How many tweets are published by the user in a given period of time?\n",
    "● Total number of tweets\n",
    "● Total number of likes and comments\n",
    "● Ratio between the number of tweets and the number of likes\n",
    "● Entropy of the user\n",
    "● Average length of the tweets per user\n",
    "● Average number of special characters in the tweets per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets_grouped_by_users = tweets.groupby(['user_id']).size()\n",
    "users['tweets_num'] = tweets_grouped_by_users\n",
    "users['tweets_num'][users['tweets_num'].isna()] = 0\n",
    "users = users.astype({'tweets_num': 'int64'})\n",
    "\n",
    "users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
