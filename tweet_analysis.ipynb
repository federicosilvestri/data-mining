{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN Only with COLAB\n",
    "\n",
    "This cell will setup notebook for running on Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://FedericoSilvestri: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@github.com/federicosilvestri/data-mining.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14702/2227366743.py:10: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "import logging as lg\n",
    "\n",
    "root = lg.getLogger()\n",
    "root.setLevel(lg.INFO)\n",
    "\n",
    "handler = lg.StreamHandler(sys.stdout)\n",
    "handler.setLevel(lg.DEBUG)\n",
    "formatter = lg.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Fetching the dataset using our native python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 14:30:57,029 - root - INFO - Pandas reading dataset tweets.csv...\n",
      "2022-10-31 14:31:50,550 - root - INFO - Pandas reading dataset users.csv...\n"
     ]
    }
   ],
   "source": [
    "from utils import fetch_dataset\n",
    "\n",
    "dataset = fetch_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1.1\n",
    "\n",
    "Exploring the dataset with analytical tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users\n",
    "\n",
    "Show `users.csv` information: types of data and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11508 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              11508 non-null  int64  \n",
      " 1   name            11507 non-null  object \n",
      " 2   lang            11508 non-null  object \n",
      " 3   bot             11508 non-null  int64  \n",
      " 4   created_at      11508 non-null  object \n",
      " 5   statuses_count  11109 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 539.6+ KB\n"
     ]
    }
   ],
   "source": [
    "users = dataset['users.csv'].copy() # make a copy\n",
    "\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en                    9970\n",
       "it                     906\n",
       "es                     319\n",
       "pt                      65\n",
       "en-gb                   50\n",
       "ru                      42\n",
       "fr                      36\n",
       "ja                      33\n",
       "zh-tw                   17\n",
       "tr                      14\n",
       "id                      12\n",
       "ko                       9\n",
       "de                       8\n",
       "nl                       6\n",
       "en-GB                    4\n",
       "ar                       3\n",
       "zh-TW                    3\n",
       "da                       2\n",
       "Select Language...       2\n",
       "en-AU                    1\n",
       "zh-cn                    1\n",
       "pl                       1\n",
       "el                       1\n",
       "fil                      1\n",
       "sv                       1\n",
       "xx-lc                    1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display lang values\n",
    "users['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have:\n",
    "\n",
    "1. `xx-lc`\n",
    "2. `Select Language...`\n",
    "\n",
    "That are not a valid language.\n",
    "We have decided to use iso639-1 Python library to detect valid languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6116\n",
       "0    5392\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display BOT values\n",
    "# 0 -> it's a human!\n",
    "# 1 -> it's a bot!\n",
    "users['bot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have clean data for `bot` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets\n",
    "\n",
    "Show `tweets.csv information: types of data and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   id              object\n",
      " 1   user_id         object\n",
      " 2   retweet_count   object\n",
      " 3   reply_count     object\n",
      " 4   favorite_count  object\n",
      " 5   num_hashtags    object\n",
      " 6   num_urls        object\n",
      " 7   num_mentions    object\n",
      " 8   created_at      object\n",
      " 9   text            object\n",
      "dtypes: object(10)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "tweets = dataset['tweets.csv'].copy()\n",
    "\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding\n",
    "\n",
    "In these cells we are going to understand and clean the data of two datasets.\n",
    "The analysis performs:\n",
    "\n",
    "1. Replacement of null values with median if type is numerical, mode if type is categorical and **outlier** timestamp value if type is datetime.\n",
    "2. Deletion of rows that has a ratio between valid values and invalid values `< k` where `k` is a param with default value 60%.\n",
    "3. Understand and replace categorical value based on their domain. For example, the language column contains invalid language codes, and we replace them with the mode value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO prof recap points for DATA UNDERSTANDING\n",
    "(last slide of data understanding)\n",
    "Checklist for Data Understanding\n",
    "- Determine the quality of the data.(e.g.syntactic accuracy)\n",
    "- Find outliers. (e. g. using visualization techniques)\n",
    "- Detect and examine missing values. Possible hidden by default values.\n",
    "- Discover new or confirm expected dependencies or correlations between attributes.\n",
    "- Check specific application dependent assumptions (e.g. the attribute follows a normal distribution)\n",
    "- Compare statistics with the expected behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definition for outlier values\n",
    "min_date = pd.Timestamp('2006-03-21') # the date when Twitter has started the activity.\n",
    "max_date = pd.Timestamp('2022-09-28') # the date when dataset has been collected.\n",
    "\n",
    "# OUTLIER constants\n",
    "OUTLIER_TIMESTAMP = pd.Timestamp('1800-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_invalid_rows(df, column_validators, ratio=0.6):\n",
    "    #\n",
    "    # This function is a generic function, that performs cleaning of rows that are invalid.\n",
    "    # We define row as invalid if the ratio between valid and invalid attributes \n",
    "    # is greater than `ratio` parameter.\n",
    "    # \n",
    "    # The validation of single attribute is entrusted to the combination of \n",
    "    # lambda function named `validator` and the fact that the attribute is nan.\n",
    "    #\n",
    "    n_null_items = int(len(column_validators) * ratio)\n",
    "    rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        count = 0\n",
    "        for head, validator in column_validators:\n",
    "            if row[head].isnull() or (validator is not None and validator(row[head])):\n",
    "                count += 1\n",
    "        if count > n_null_items:\n",
    "            rows.append(i)\n",
    "    df.drop(df.index[rows], inplace=True)\n",
    "    return rows\n",
    "\n",
    "# Definition of generic lambda validator functions\n",
    "check_int = lambda label: not bool(re.search(r'^(\\d)+(\\.0+)?$', str(label))) # checks, using regex if attribute is integer\n",
    "check_positive_int = lambda label: check_int(label) or float(label) < 0 # checks if label is positive\n",
    "check_date = lambda label: pd.Timestamp(label) < min_date or pd.Timestamp(label) > max_date # checks timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-30 20:57:08,938 - root - INFO - Deleted rows: 0\n"
     ]
    }
   ],
   "source": [
    "from langcodes import tag_is_valid # import the library for ISO639-1 codes\n",
    "\n",
    "# For each column define a validator.\n",
    "column_validators = [\n",
    "    ('id', check_int),\n",
    "    ('name', None),\n",
    "    ('lang', tag_is_valid),\n",
    "    ('bot', lambda label: label == '1' or label == '0'),\n",
    "    ('statuses_count', check_int),\n",
    "    ('created_at', check_date),\n",
    "]\n",
    "\n",
    "#\n",
    "# Execute the cleaning function.\n",
    "#\n",
    "deleted_rows = clean_invalid_rows(users, column_validators)\n",
    "lg.info(f\"Deleted rows: {len(deleted_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Replacement of invalid names\n",
    "#\n",
    "users['name'].replace(np.nan, '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6116\n",
       "0    5392\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Explore bot column\n",
    "#\n",
    "users['bot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all values of column bot are 0,1 so we can convert it into boolean field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting to bool\n",
    "users = users.astype({'bot': 'bool'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       9973\n",
       "it        906\n",
       "es        319\n",
       "pt         65\n",
       "en-gb      54\n",
       "ru         42\n",
       "fr         36\n",
       "ja         33\n",
       "zh-tw      20\n",
       "tr         14\n",
       "id         12\n",
       "ko          9\n",
       "de          8\n",
       "nl          6\n",
       "ar          3\n",
       "da          2\n",
       "en-au       1\n",
       "zh-cn       1\n",
       "pl          1\n",
       "el          1\n",
       "fil         1\n",
       "sv          1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Replacement of invalid languages\n",
    "#\n",
    "\n",
    "# first normalize to lower case all langs\n",
    "users['lang'] = users['lang'].str.lower()\n",
    "\n",
    "# calculate the mode for this categorical value\n",
    "user_lang_mode = users['lang'].mode()[0]\n",
    "\n",
    "# lambda function for substition\n",
    "lang_subst_lambda = lambda x: x if tag_is_valid(x) else user_lang_mode\n",
    "\n",
    "# execute substitution\n",
    "users['lang'].map(lang_subst_lambda).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define a constant that marks an attribute as an outlier.\n",
    "#\n",
    "\n",
    "def filter_datetime(df, att):\n",
    "    def parse_and_check_datetime(el):\n",
    "        try:\n",
    "            datetime = pd.Timestamp(el) # parse datetime as Timestamp\n",
    "            # checks validity\n",
    "            if datetime < min_date or datetime > max_date:\n",
    "                # is an outlier\n",
    "                return OUTLIER_TIMESTAMP\n",
    "            else:\n",
    "                # is not an outlier\n",
    "                return datetime\n",
    "        except ValueError:\n",
    "            # cannot parse as timestamp, it's an outlier\n",
    "            return OUTLIER_TIMESTAMP\n",
    "\n",
    "    df[att] = df[att].map(parse_and_check_datetime)\n",
    "\n",
    "    return df.astype({att: 'datetime64[ns]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter to datetime column\n",
    "users = filter_datetime(users, 'created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Handling the statuses_count column.\n",
    "#\n",
    "status_count_median = users['statuses_count'].median()\n",
    "\n",
    "# replace the null values with median\n",
    "users['statuses_count'].fillna(status_count_median, inplace=True)\n",
    "\n",
    "# Convert the column `status_count` to int64 type.\n",
    "users = users.astype({'statuses_count': 'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-30 20:57:09,096 - root - INFO - Starting removing duplicates\n",
      "2022-10-30 20:57:09,109 - root - INFO - Number of duplicates = 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Removing duplicate records.\n",
    "#\n",
    "lg.info(\"Starting removing duplicates\")\n",
    "initial_size = len(users)\n",
    "users = users.drop_duplicates()\n",
    "lg.info(f\"Number of duplicates = {initial_size - len(users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11508 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id              11508 non-null  int64         \n",
      " 1   name            11508 non-null  object        \n",
      " 2   lang            11508 non-null  object        \n",
      " 3   bot             11508 non-null  bool          \n",
      " 4   created_at      11508 non-null  datetime64[ns]\n",
      " 5   statuses_count  11508 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 550.7+ KB\n"
     ]
    }
   ],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all the columns are now validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>bot</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11508</td>\n",
       "      <td>11508</td>\n",
       "      <td>11508</td>\n",
       "      <td>11508.000000</td>\n",
       "      <td>11508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11361</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sara</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>9970</td>\n",
       "      <td>6116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5681.686566</td>\n",
       "      <td>2017-10-03 21:23:16.013121280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012-01-24 01:57:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2017-01-18 09:50:16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2018-01-30 17:20:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2520.250000</td>\n",
       "      <td>2019-02-25 00:17:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399555.000000</td>\n",
       "      <td>2020-04-21 07:28:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18769.594489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   lang    bot  statuses_count                     created_at\n",
       "count   11508  11508  11508    11508.000000                          11508\n",
       "unique  11361     24      2             NaN                            NaN\n",
       "top      Sara     en   True             NaN                            NaN\n",
       "freq        7   9970   6116             NaN                            NaN\n",
       "mean      NaN    NaN    NaN     5681.686566  2017-10-03 21:23:16.013121280\n",
       "min       NaN    NaN    NaN        0.000000            2012-01-24 01:57:38\n",
       "25%       NaN    NaN    NaN       42.000000     2017-01-18 09:50:16.500000\n",
       "50%       NaN    NaN    NaN       68.000000            2018-01-30 17:20:36\n",
       "75%       NaN    NaN    NaN     2520.250000            2019-02-25 00:17:30\n",
       "max       NaN    NaN    NaN   399555.000000            2020-04-21 07:28:31\n",
       "std       NaN    NaN    NaN    18769.594489                            NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Describe the pre-processed dataset with all columns.\n",
    "#\n",
    "users[['name', 'lang', 'bot', 'statuses_count', 'created_at']].describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define a function for validating text of tweet.\n",
    "#\n",
    "check_text = lambda x: not x or len(str(x)) <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 10:40:50,728 - root - INFO - Starting dataset cleaning with validators...\n",
      "2022-10-31 11:21:23,251 - root - INFO - Deleted rows 16490\n"
     ]
    }
   ],
   "source": [
    "column_validators = [\n",
    "    ('id', check_positive_int),\n",
    "    ('user_id', check_positive_int),\n",
    "    ('retweet_count', check_positive_int),\n",
    "    ('reply_count', check_positive_int),\n",
    "    ('favorite_count', check_positive_int),\n",
    "    ('num_hashtags', check_positive_int),\n",
    "    ('num_urls', check_positive_int),\n",
    "    ('num_mentions', check_positive_int),\n",
    "    ('created_at', check_date),\n",
    "    ('text', check_text),\n",
    "]\n",
    "\n",
    "# clean the dataset using validators ratio function.\n",
    "lg.info(\"Starting dataset cleaning with validators...\")\n",
    "deleted_rows = clean_invalid_rows(tweets, column_validators)\n",
    "lg.info(f\"Deleted rows {len(deleted_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to remove the `id` column because it's not relevant to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Dropping id column\n",
    "#\n",
    "tweets = tweets.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze all columns\n",
    "\n",
    "The followings cells perform analysis on type and convert invalid type in an OUTLIER_VALUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 11:32:54,771 - root - INFO - -1            431004\n",
      "497404180       4600\n",
      "7004532         4580\n",
      "157029836       4578\n",
      "1693274954      4572\n",
      "               ...  \n",
      "5915               1\n",
      "605294402          1\n",
      "2350               1\n",
      "2583               1\n",
      "261                1\n",
      "Name: user_id, Length: 12171, dtype: int64\n",
      "2022-10-31 11:32:55,640 - root - INFO - 0             9419279\n",
      "1             1171971\n",
      "2              357074\n",
      "3              180180\n",
      "4              111519\n",
      "               ...   \n",
      "qzf                 1\n",
      "zl0v                1\n",
      "lsgc4               1\n",
      "tej9sl6m0           1\n",
      "rf24duucpb          1\n",
      "Name: retweet_count, Length: 228814, dtype: int64\n",
      "2022-10-31 11:32:56,347 - root - INFO - 0             11790440\n",
      "0.0            1042490\n",
      "1                15670\n",
      "2                 1454\n",
      "1.0               1435\n",
      "                ...   \n",
      "gmo82                1\n",
      "brs                  1\n",
      "wh9v7rkff3           1\n",
      "zszac                1\n",
      "otsduzr              1\n",
      "Name: reply_count, Length: 158619, dtype: int64\n",
      "2022-10-31 11:32:57,160 - root - INFO - 0             9467209\n",
      "1             1408466\n",
      "0.0            837480\n",
      "2              407252\n",
      "3              183342\n",
      "               ...   \n",
      "glddf               1\n",
      "w4g6fy5fn5          1\n",
      "4200                1\n",
      "uvu1qbo             1\n",
      "l25suv5             1\n",
      "Name: favorite_count, Length: 158763, dtype: int64\n",
      "2022-10-31 11:32:57,853 - root - INFO - 0             10470209\n",
      "1               911568\n",
      "0.0             613593\n",
      "2               270666\n",
      "3                88101\n",
      "                ...   \n",
      "q5r                  1\n",
      "gdvfamvz             1\n",
      "kvo4ljv              1\n",
      "pwrziwmqjt           1\n",
      "kmmt7p21sf           1\n",
      "Name: num_hashtags, Length: 104779, dtype: int64\n",
      "2022-10-31 11:32:58,547 - root - INFO - 0             9894198\n",
      "1             1890891\n",
      "0.0            875494\n",
      "1.0            166751\n",
      "2               23770\n",
      "               ...   \n",
      "lsxkylf8ja          1\n",
      "4ag3wv2             1\n",
      "yndy3xfe9w          1\n",
      "mg1d4               1\n",
      "ix0n                1\n",
      "Name: num_urls, Length: 156930, dtype: int64\n",
      "2022-10-31 11:32:59,196 - root - INFO - 0             7561627\n",
      "1             4106916\n",
      "2              718190\n",
      "3              174700\n",
      "4               55558\n",
      "               ...   \n",
      "kko                 1\n",
      "ax5omik1h           1\n",
      "9067                1\n",
      "fwa5b3y3h6          1\n",
      "8155oi              1\n",
      "Name: num_mentions, Length: 131538, dtype: int64\n",
      "2022-10-31 11:33:13,125 - root - INFO - 2020-04-04 03:43:02    133\n",
      "2020-04-04 03:43:01     92\n",
      "2020-04-04 05:01:46     84\n",
      "2020-04-04 05:01:47     75\n",
      "2020-04-04 03:23:46     49\n",
      "                      ... \n",
      "2020-01-21 03:34:06      1\n",
      "2020-04-06 19:03:41      1\n",
      "2019-11-02 03:44:58      1\n",
      "2017-08-13 20:10:57      1\n",
      "2019-07-10 12:00:00      1\n",
      "Name: created_at, Length: 8127084, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Take `retweet_count` column as an example.\n",
    "#\n",
    "for col in tweets.columns:\n",
    "    if col == 'text':\n",
    "        #\n",
    "        # skip the text column\n",
    "        #\n",
    "        continue\n",
    "    lg.info(tweets[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have a lot of invalid values, hence we need to replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function that replaces invalid values with an outlier value\n",
    "def replace_with_outlier(dataset, col_name, check_function, outlier_value):\n",
    "    df = dataset.copy()\n",
    "    v = df[col_name].map(check_function)\n",
    "    record_touched = len(v) - sum(v)\n",
    "    df.loc[v == False, col_name] = df[v == False][col_name].apply(lambda x: outlier_value)\n",
    "    return df, record_touched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check function for integer values\n",
    "def check_integer_column(x):\n",
    "    try:\n",
    "        # we try to cast to int\n",
    "        int(str(x))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all columns to be checked\n",
    "INTEGER_COLUMNS = [\n",
    "    'user_id',\n",
    "    'retweet_count',\n",
    "    'reply_count',\n",
    "    'favorite_count',\n",
    "    'num_hashtags',\n",
    "    'num_urls',\n",
    "    'num_mentions',\n",
    "]\n",
    "\n",
    "# outlier value\n",
    "OUTLIER_VALUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 14:35:35,990 - root - INFO - Detected 0 user_id with invalid value, i.e. 0.0% of dataset\n",
      "2022-10-31 14:35:45,264 - root - INFO - Detected 0 retweet_count with invalid value, i.e. 0.0% of dataset\n",
      "2022-10-31 14:35:53,338 - root - INFO - Detected 0 reply_count with invalid value, i.e. 0.0% of dataset\n",
      "2022-10-31 14:36:06,502 - root - INFO - Detected 1853922 favorite_count with invalid value, i.e. 13.567239256548408% of dataset\n",
      "2022-10-31 14:36:18,503 - root - INFO - Detected 1854130 num_hashtags with invalid value, i.e. 13.568761427257511% of dataset\n",
      "2022-10-31 14:36:30,111 - root - INFO - Detected 1853914 num_urls with invalid value, i.e. 13.567180711521134% of dataset\n",
      "2022-10-31 14:36:40,845 - root - INFO - Detected 988054 num_mentions with invalid value, i.e. 7.2307060471744125% of dataset\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Replace invalid integer columns\n",
    "#\n",
    "for col in INTEGER_COLUMNS:\n",
    "    tweets, removed = replace_with_outlier(\n",
    "        tweets,\n",
    "        col,\n",
    "        check_integer_column,\n",
    "        OUTLIER_VALUE,\n",
    "    )\n",
    "    lg.info(f\"Detected {removed} {col} with invalid value, i.e. {removed / len(tweets) * 100}% of dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical columns, replace with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a simple function that replaces missing values with the median (only numerical)\n",
    "def clean_with_median(dataset, col_name):\n",
    "    df = dataset.copy()\n",
    "    v = df[col_name].map(lambda x: x != OUTLIER_VALUE)\n",
    "    median = df[v == True][col_name].median()\n",
    "    df.loc[v == False, col_name] = df[v == False][col_name].apply(lambda x: median)\n",
    "    \n",
    "    return df, sum(~v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 14:37:35,693 - root - INFO - Detected 434013 rows with outlier value i.e. 3.1761628652404705% of dataset\n",
      "2022-10-31 14:37:46,931 - root - INFO - Detected 625542 rows with outlier value i.e. 4.577796681316584% of dataset\n",
      "2022-10-31 14:37:57,852 - root - INFO - Detected 1853912 rows with outlier value i.e. 13.567166075264318% of dataset\n",
      "2022-10-31 14:38:08,988 - root - INFO - Detected 1853922 rows with outlier value i.e. 13.567239256548408% of dataset\n",
      "2022-10-31 14:38:19,971 - root - INFO - Detected 1854130 rows with outlier value i.e. 13.568761427257511% of dataset\n",
      "2022-10-31 14:38:31,098 - root - INFO - Detected 1853914 rows with outlier value i.e. 13.567180711521134% of dataset\n",
      "2022-10-31 14:38:42,264 - root - INFO - Detected 988054 rows with outlier value i.e. 7.2307060471744125% of dataset\n"
     ]
    }
   ],
   "source": [
    "# Replacing missing data with median\n",
    "for col in INTEGER_COLUMNS:\n",
    "    tweets, affected = clean_with_median(tweets, col)\n",
    "    lg.info(f'Detected {affected} rows with outlier value i.e. {affected / len(tweets) * 100}% of dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing the text column, we want to make the column a string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:10:55,925 - root - INFO - Found 0 records, i.e. 0.0% of dataset\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Compute statistics\n",
    "#\n",
    "invalid_texts = tweets['text'].map(pd.isnull)\n",
    "lg.info(f\"Found {sum(invalid_texts)} records, i.e. {sum(invalid_texts) / len(invalid_texts) * 100}% of dataset\")\n",
    "# to optize the memory\n",
    "del invalid_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the text record\n",
    "def handle_text_record(x):\n",
    "    if pd.isnull(x):\n",
    "        return ''\n",
    "    else:\n",
    "        return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327746321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-11 14:53:55</td>\n",
       "      <td>If man is a little lower than angels, then ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333722906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-01 20:27:04</td>\n",
       "      <td>\"@BestWSHHVids: how do you say these words wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2379755827</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-02 13:34:31</td>\n",
       "      <td>@LOLatComedy awsome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>466226882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-04 07:17:37</td>\n",
       "      <td>Stephen Hawkins: i buchi neri non esistono se ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1355537995</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-11 16:45:31</td>\n",
       "      <td>RT @tibbs_montris: So ready for Wednesday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13664690</th>\n",
       "      <td>220933018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-04 05:29:33</td>\n",
       "      <td>ESTA MANANA AUN ESTA  MUY FRIO ! MIREN ESTO ! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13664691</th>\n",
       "      <td>587491046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-17 02:51:53</td>\n",
       "      <td>@warriors Congrats, maybe I'll be able to get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13664693</th>\n",
       "      <td>91781300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-07-10 22:43:09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13664694</th>\n",
       "      <td>127895572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-07 19:56:55</td>\n",
       "      <td>Shooting crew of porn movies. #TheWorstJobToHave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13664695</th>\n",
       "      <td>465421036</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-10 12:00:00</td>\n",
       "      <td>Qualcuno dovrÃ  pur dire a quelli che \"Twitter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11711019 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id retweet_count reply_count favorite_count num_hashtags  \\\n",
       "0          327746321             0           0              0            0   \n",
       "1          333722906             1           0              0            0   \n",
       "2         2379755827             0           0              0            0   \n",
       "3          466226882             0           0              0            0   \n",
       "4         1355537995           114           0              0            1   \n",
       "...              ...           ...         ...            ...          ...   \n",
       "13664690   220933018             0           0              0            0   \n",
       "13664691   587491046             0           0              0            0   \n",
       "13664693    91781300             0         0.0            0.0          0.0   \n",
       "13664694   127895572             0           0              1            1   \n",
       "13664695   465421036             3           0              4            0   \n",
       "\n",
       "         num_urls num_mentions          created_at  \\\n",
       "0               0            0 2019-09-11 14:53:55   \n",
       "1               0            1 2020-04-01 20:27:04   \n",
       "2               0            1 2019-05-02 13:34:31   \n",
       "3               0            0 2019-11-04 07:17:37   \n",
       "4               0            1 2020-03-11 16:45:31   \n",
       "...           ...          ...                 ...   \n",
       "13664690        0            0 2018-05-04 05:29:33   \n",
       "13664691        0            1 2020-04-17 02:51:53   \n",
       "13664693      0.0          0.0 2016-07-10 22:43:09   \n",
       "13664694        0            0 2019-03-07 19:56:55   \n",
       "13664695        0            0 2019-07-10 12:00:00   \n",
       "\n",
       "                                                       text  \n",
       "0         If man is a little lower than angels, then ang...  \n",
       "1         \"@BestWSHHVids: how do you say these words wit...  \n",
       "2                                       @LOLatComedy awsome  \n",
       "3         Stephen Hawkins: i buchi neri non esistono se ...  \n",
       "4               RT @tibbs_montris: So ready for Wednesday!   \n",
       "...                                                     ...  \n",
       "13664690  ESTA MANANA AUN ESTA  MUY FRIO ! MIREN ESTO ! ...  \n",
       "13664691  @warriors Congrats, maybe I'll be able to get ...  \n",
       "13664693                                                     \n",
       "13664694   Shooting crew of porn movies. #TheWorstJobToHave  \n",
       "13664695  Qualcuno dovrÃ  pur dire a quelli che \"Twitter...  \n",
       "\n",
       "[11711019 rows x 9 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the function\n",
    "tweets['text'] = tweets['text'].map(handle_text_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Managing the Datetime column\n",
    "#\n",
    "tweets = filter_datetime(tweets, 'created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Casting all dataset\n",
    "#\n",
    "tweets = tweets.astype({\n",
    "    'user_id': 'int64',\n",
    "    'retweet_count': 'int64',\n",
    "    'reply_count': 'int64',\n",
    "    'favorite_count': 'int64',\n",
    "    'num_hashtags': 'int64',\n",
    "    'num_urls': 'int64',\n",
    "    'num_mentions': 'int64',\n",
    "    'created_at': 'datetime64[ns]',\n",
    "    'text': 'string',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:21:02,911 - root - INFO - Removed 0 duplicates record that are 0.0% of dataset.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Printing statistics about cleaning\n",
    "#\n",
    "\n",
    "initial_ds_len = len(tweets)\n",
    "tweets = tweets.drop_duplicates()\n",
    "lg.info(f'Removed {initial_ds_len - len(tweets)} duplicates record that are {(initial_ds_len - len(tweets)) / initial_ds_len * 100}% of dataset.')\n",
    "del initial_ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11249771 entries, 0 to 13664695\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   user_id         int64         \n",
      " 1   retweet_count   int64         \n",
      " 2   reply_count     int64         \n",
      " 3   favorite_count  int64         \n",
      " 4   num_hashtags    int64         \n",
      " 5   num_urls        int64         \n",
      " 6   num_mentions    int64         \n",
      " 7   created_at      datetime64[ns]\n",
      " 8   text            string        \n",
      "dtypes: datetime64[ns](1), int64(7), string(1)\n",
      "memory usage: 858.3 MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3337/1761588424.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  tweets.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "      <td>11265103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11242504</td>\n",
       "      <td>12170</td>\n",
       "      <td>45814</td>\n",
       "      <td>645</td>\n",
       "      <td>1570</td>\n",
       "      <td>312</td>\n",
       "      <td>450</td>\n",
       "      <td>394</td>\n",
       "      <td>8029865</td>\n",
       "      <td>6778479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>dpy</td>\n",
       "      <td>491630583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1800-01-01 00:00:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>3929</td>\n",
       "      <td>7771921</td>\n",
       "      <td>9841583</td>\n",
       "      <td>7903049</td>\n",
       "      <td>8739113</td>\n",
       "      <td>8259047</td>\n",
       "      <td>6253434</td>\n",
       "      <td>97605</td>\n",
       "      <td>406989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-03 10:36:12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    user_id retweet_count reply_count favorite_count  \\\n",
       "count   11265103   11265103      11265103    11265103       11265103   \n",
       "unique  11242504      12170         45814         645           1570   \n",
       "top          dpy  491630583             0           0              0   \n",
       "freq          10       3929       7771921     9841583        7903049   \n",
       "first        NaN        NaN           NaN         NaN            NaN   \n",
       "last         NaN        NaN           NaN         NaN            NaN   \n",
       "\n",
       "       num_hashtags  num_urls num_mentions           created_at      text  \n",
       "count      11265103  11265103     11265103             11265103  11265103  \n",
       "unique          312       450          394              8029865   6778479  \n",
       "top               0         0            0  1800-01-01 00:00:00            \n",
       "freq        8739113   8259047      6253434                97605    406989  \n",
       "first           NaN       NaN          NaN  1800-01-01 00:00:00       NaN  \n",
       "last            NaN       NaN          NaN  2020-05-03 10:36:12       NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Save the CSV\n",
    "#\n",
    "tweets.to_csv('tweets_cleaned.csv')\n",
    "users.to_csv('users_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def build_grid_plot(configs):\n",
    "    cols = 2 if len(configs) <= 4 else 3\n",
    "    rows = math.ceil(len(configs) / cols)\n",
    "    fig_dims = (rows, cols)\n",
    "    fig = plt.figure(figsize=(20, rows * 5))\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "    for i, config in enumerate(configs):\n",
    "        if i == len(configs) - 1 and len(configs) % cols == 1 and cols % 2 == 1:\n",
    "            plt.subplot2grid(fig_dims, (i // cols, cols // 2))\n",
    "        else:\n",
    "            plt.subplot2grid(fig_dims, (i // cols, i % cols))\n",
    "        if config['type'] == 'hist':\n",
    "            config['column'].hist(bins=int(math.log2(len(config['column'])) + 1))\n",
    "            plt.title(config['title'])\n",
    "        elif config['type'] == 'bar':\n",
    "            config['column'].value_counts().plot(kind='bar', title=config['title'])\n",
    "            if ('rotation' in config) and config['rotation']:\n",
    "                plt.xticks(rotation=0)\n",
    "        elif config['type'] == 'boxplot':\n",
    "            config['df'].boxplot(column=config['columns'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['retweet_count'],\n",
    "        'title': 'Retweet Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['reply_count'],\n",
    "        'title': 'Replay Counts',\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['favorite_count'],\n",
    "        'title': 'Favorite Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['num_hashtags'],\n",
    "        'title': 'Hashtag Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['num_urls'],\n",
    "        'title': 'Url Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['num_mentions'],\n",
    "        'title': 'Mentions Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': tweets['created_at'],\n",
    "        'title': 'Tweets Creation Date Distribution'\n",
    "    }\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['statuses_count'],\n",
    "        'title': 'Statues Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'bar',\n",
    "        'column': users['bot'].map(lambda v: 'Bot' if v else 'User'),\n",
    "        'title': 'Bot and User Counts',\n",
    "        'rotation': True\n",
    "    },\n",
    "    {\n",
    "        'type': 'bar',\n",
    "        'column': users['lang'],\n",
    "        'title': 'Languages Counts'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['created_at'],\n",
    "        'title': 'User Creation Date Distribution'\n",
    "    }\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_outliers(df, column_name, threshold):\n",
    "    column = df[column_name]\n",
    "    to_replace = len(column[column > threshold])\n",
    "    perc_to_replace = (to_replace / len(column) * 100)\n",
    "    lg.info(f'{to_replace} ({perc_to_replace:.2f}%) element replaced for column {column_name}')\n",
    "    median = column.median()\n",
    "    df[column_name] = column.map(lambda x: median if x > threshold else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def boxplot_tweets_show():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['retweet_count']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['reply_count']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['favorite_count']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_hashtags']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_urls']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_mentions']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "boxplot_tweets_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "replace_outliers(tweets, 'retweet_count', 6e5)\n",
    "replace_outliers(tweets, 'reply_count', 6e4)\n",
    "replace_outliers(tweets, 'favorite_count', 1.2e5)\n",
    "replace_outliers(tweets, 'num_hashtags', 1e4)\n",
    "replace_outliers(tweets, 'num_urls', 1e4)\n",
    "replace_outliers(tweets, 'num_mentions', 1e5)\n",
    "\n",
    "boxplot_tweets_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "tweets.plot.scatter(x='reply_count', y='favorite_count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TASK 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many tweets were published by the user?\n",
    "- How many tweets are published by the user in a given period of time?\n",
    "- Total number of tweets\n",
    "- Total number of likes and comments\n",
    "- Ratio between the number of tweets and the number of likes\n",
    "- Entropy of the user\n",
    "- Average length of the tweets per user\n",
    "- Average number of special characters in the tweets per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "column_name = 'tweets_num'\n",
    "tweets_grouped_by_users = tweets.groupby(['user_id']).size()\n",
    "users[column_name] = tweets_grouped_by_users\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_greater_2020 = tweets[tweets['created_at'] >= pd.Timestamp('2020-01-01')]\n",
    "tweets_filtered_2020 = tweets_greater_2020[tweets['created_at'] < pd.Timestamp('2021-01-01')]\n",
    "tweets_grouped_2020 = tweets_filtered_2020.groupby(['user_id']).size()\n",
    "\n",
    "column_name = 'tweets_2020_num'\n",
    "users[column_name] = tweets_grouped_2020\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'tweets_total_num'\n",
    "users[column_name] = users['statuses_count'] + users['tweets_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'likes_num'\n",
    "tweets_grouped_likes = tweets.rename(columns={'favorite_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_likes, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'comments_num'\n",
    "tweets_grouped_comments = tweets.rename(columns={'reply_count': column_name}).groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'ratio_tweets_likes'\n",
    "users[column_name] = users['tweets_total_num'] / users['likes_num']\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'entropy'\n",
    "avg_tweets_total_num = users['tweets_total_num'] / users['tweets_total_num'].sum()\n",
    "users[column_name] = - (avg_tweets_total_num * np.log(avg_tweets_total_num))\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'float64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_total_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(lambda t: len(t))\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'texts_special_chars_length'\n",
    "tmp_tweets = tweets.rename(columns={'text': column_name})\n",
    "\n",
    "def count_special_chars(text):\n",
    "    count = 0\n",
    "    for ch in text:\n",
    "        if not ch.isalpha() and not ch.isdigit():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "tmp_tweets[column_name] = tmp_tweets[column_name].map(count_special_chars)\n",
    "tweets_grouped_comments = tmp_tweets.groupby(['user_id'])[column_name].sum()\n",
    "\n",
    "users = users.join(tweets_grouped_comments, on='id')\n",
    "\n",
    "users[column_name].replace(np.nan, 0, inplace=True)\n",
    "users = users.astype({column_name: 'int64'})\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the team has to explore the new features for a statistical analysis (distributions, outliers, visualizations, correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_num'],\n",
    "        'title': 'Tweets num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_2020_num'],\n",
    "        'title': 'Tweets 2020 num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['tweets_total_num'],\n",
    "        'title': 'Tweets total num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['likes_num'],\n",
    "        'title': 'Likes num'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['comments_num'],\n",
    "        'title': 'Comments num'\n",
    "    },\n",
    "    #{ # TODO GERE: inf values, understand how plot it\n",
    "    #    'type': 'hist',\n",
    "    #    'column': users['ratio_tweets_likes'],\n",
    "    #    'title': 'Ratio tweets likes'\n",
    "    #},\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['entropy'],\n",
    "        'title': 'Entropy'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_total_length'],\n",
    "        'title': 'Texts total length'\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['texts_special_chars_length'],\n",
    "        'title': 'Texts special chars length'\n",
    "    },\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_tweets_newfeatures_show():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_2020_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['tweets_total_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['likes_num']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['comments_num']\n",
    "        },\n",
    "        #{\n",
    "        #    'type': 'boxplot',\n",
    "        #    'df': users,\n",
    "        #    'columns': ['ratio_tweets_likes']\n",
    "        #},\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['entropy']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_total_length']\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': users,\n",
    "            'columns': ['texts_special_chars_length']\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)\n",
    "\n",
    "boxplot_tweets_newfeatures_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
