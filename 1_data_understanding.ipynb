{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DM - Data understanding [TASK 1.1]\n",
    "\n",
    "Exploring the dataset with analytical tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN Only with COLAB\n",
    "\n",
    "This cell will setup notebook for running on Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://FedericoSilvestri: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@github.com/federicosilvestri/data-mining.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd data-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284507/3431428609.py:12: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import sys\n",
    "import logging as lg\n",
    "import os\n",
    "from utils.validators import check_bot, check_date, check_int, check_positive_int, check_text, MAX_DATE, MIN_DATE\n",
    "\n",
    "\n",
    "root = lg.getLogger()\n",
    "root.setLevel(lg.INFO)\n",
    "\n",
    "\n",
    "nb_workers = int(os.cpu_count() / 2 + 1)\n",
    "\n",
    "handler = lg.StreamHandler(sys.stdout)\n",
    "handler.setLevel(lg.DEBUG)\n",
    "formatter = lg.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "pandarallel.initialize(\n",
    "    progress_bar=True,\n",
    "    nb_workers=nb_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Fetching the dataset using our native python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:12:52,562 - root - INFO - Pandas reading dataset tweets.csv...\n",
      "2022-11-02 21:13:23,345 - root - INFO - Pandas reading dataset users.csv...\n"
     ]
    }
   ],
   "source": [
    "from utils import fetch_dataset\n",
    "\n",
    "dataset = fetch_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users\n",
    "\n",
    "Show `users.csv` information: types of data and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11508 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              11508 non-null  int64  \n",
      " 1   name            11507 non-null  object \n",
      " 2   lang            11508 non-null  object \n",
      " 3   bot             11508 non-null  int64  \n",
      " 4   created_at      11508 non-null  object \n",
      " 5   statuses_count  11109 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 539.6+ KB\n"
     ]
    }
   ],
   "source": [
    "users = dataset['users.csv'].copy() # make a copy\n",
    "\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en                    9970\n",
       "it                     906\n",
       "es                     319\n",
       "pt                      65\n",
       "en-gb                   50\n",
       "ru                      42\n",
       "fr                      36\n",
       "ja                      33\n",
       "zh-tw                   17\n",
       "tr                      14\n",
       "id                      12\n",
       "ko                       9\n",
       "de                       8\n",
       "nl                       6\n",
       "en-GB                    4\n",
       "ar                       3\n",
       "zh-TW                    3\n",
       "da                       2\n",
       "Select Language...       2\n",
       "en-AU                    1\n",
       "zh-cn                    1\n",
       "pl                       1\n",
       "el                       1\n",
       "fil                      1\n",
       "sv                       1\n",
       "xx-lc                    1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display lang values\n",
    "users['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have:\n",
    "\n",
    "1. `xx-lc`\n",
    "2. `Select Language...`\n",
    "\n",
    "That are not a valid language.\n",
    "We have decided to use iso639-1 Python library to detect valid languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6116\n",
       "0    5392\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display BOT values\n",
    "# 0 -> it's a human!\n",
    "# 1 -> it's a bot!\n",
    "users['bot'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have clean data for `bot` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets\n",
    "\n",
    "Show `tweets.csv information: types of data and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Dtype \n",
      "---  ------          ----- \n",
      " 0   id              object\n",
      " 1   user_id         object\n",
      " 2   retweet_count   object\n",
      " 3   reply_count     object\n",
      " 4   favorite_count  object\n",
      " 5   num_hashtags    object\n",
      " 6   num_urls        object\n",
      " 7   num_mentions    object\n",
      " 8   created_at      object\n",
      " 9   text            object\n",
      "dtypes: object(10)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "tweets = dataset['tweets.csv'].copy()\n",
    "\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality assessment and data cleaning\n",
    "\n",
    "In these cells we are going to understand and clean the data of two datasets.\n",
    "The analysis performs:\n",
    "\n",
    "1. Replacement of null values with median if type is numerical, mode if type is categorical and **outlier** timestamp value if type is datetime.\n",
    "2. Deletion of rows that has a ratio between valid values and invalid values `< k` where `k` is a param with default value 60%.\n",
    "3. Understand and replace categorical value based on their domain. For example, the language column contains invalid language codes, and we replace them with the mode value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTLIER constants\n",
    "OUTLIER_TIMESTAMP = pd.Timestamp('1800-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_invalid_rows(df, column_validators, ratio=0.3):\n",
    "    #\n",
    "    # This function is a generic function, that performs cleaning of rows that are invalid.\n",
    "    # We define row as invalid if the ratio between valid and invalid attributes \n",
    "    # is greater than `ratio` parameter.\n",
    "    # \n",
    "    # The validation of single attribute is entrusted to the combination of \n",
    "    # lambda function named `validator` and the fact that the attribute is nan.\n",
    "    #\n",
    "    def check_invalid_rows_callback(row) -> bool:\n",
    "        # this function must return True if record is to be deleted.\n",
    "        invalid_count = 0\n",
    "        \n",
    "        for head, validator in column_validators:\n",
    "            value = row[head]\n",
    "            if pd.isnull(value):\n",
    "                invalid_count += 1\n",
    "            else:\n",
    "                if validator is not None and not validator(value):\n",
    "                    invalid_count += 1\n",
    "        return float(invalid_count / len(column_validators)) > ratio\n",
    "\n",
    "    trash = df.parallel_apply(check_invalid_rows_callback, axis=1)\n",
    "    return df[~trash], sum(trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb35688ef3445fe8aa82f32f6295275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2302), Label(value='0 / 2302'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:13:25,535 - root - INFO - Deleted rows 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "from langcodes import tag_is_valid # import the library for ISO639-1 codes\n",
    "\n",
    "# For each column define a validator.\n",
    "column_validators = [\n",
    "    ('id', check_positive_int),\n",
    "    ('name', check_text),\n",
    "    ('lang', tag_is_valid),\n",
    "    ('bot', check_bot),\n",
    "    ('statuses_count', check_positive_int),\n",
    "    ('created_at', check_date),\n",
    "]\n",
    "\n",
    "#\n",
    "# Execute the cleaning function.\n",
    "#\n",
    "users, deleted_rows = clean_invalid_rows(users, column_validators)\n",
    "lg.info(f\"Deleted rows {deleted_rows} ({deleted_rows / len(users)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:13:50,756 - root - INFO - Found 1 records, i.e. 0.008689607229753215% of dataset\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Replacement of invalid names\n",
    "#\n",
    "invalid_names = users['name'].map(pd.isnull)\n",
    "lg.info(f\"Found {sum(invalid_names)} records, i.e. {sum(invalid_names) / len(invalid_names) * 100}% of dataset\")\n",
    "# to optize the memory\n",
    "del invalid_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6116\n",
       "0    5392\n",
       "Name: bot, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Explore bot column\n",
    "#\n",
    "users['bot'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6acd9dd7d784bc197707c3b67e0f3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2302), Label(value='0 / 2302'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Clean missing user names\n",
    "#\n",
    "users['name'] = users['name'].parallel_map(lambda t: '' if pd.isnull(t) else t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all values of column bot are 0,1 so we can convert it into boolean field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       9973\n",
       "it        906\n",
       "es        319\n",
       "pt         65\n",
       "en-gb      54\n",
       "ru         42\n",
       "fr         36\n",
       "ja         33\n",
       "zh-tw      20\n",
       "tr         14\n",
       "id         12\n",
       "ko          9\n",
       "de          8\n",
       "nl          6\n",
       "ar          3\n",
       "da          2\n",
       "en-au       1\n",
       "zh-cn       1\n",
       "pl          1\n",
       "el          1\n",
       "fil         1\n",
       "sv          1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Replacement of invalid languages\n",
    "#\n",
    "\n",
    "# first normalize to lower case all langs\n",
    "users['lang'] = users['lang'].str.lower()\n",
    "\n",
    "# calculate the mode for this categorical value\n",
    "user_lang_mode = users['lang'].mode()[0]\n",
    "\n",
    "# lambda function for substition\n",
    "lang_subst_lambda = lambda x: x if tag_is_valid(x) else user_lang_mode\n",
    "\n",
    "# execute substitution\n",
    "users['lang'] = users['lang'].map(lang_subst_lambda)\n",
    "\n",
    "users['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define a constant that marks an attribute as an outlier.\n",
    "#\n",
    "\n",
    "def filter_datetime(df, att):\n",
    "    def parse_and_check_datetime(el):\n",
    "        try:\n",
    "            datetime = pd.Timestamp(el) # parse datetime as Timestamp\n",
    "            # checks validity\n",
    "            if datetime < MIN_DATE or datetime > MAX_DATE:\n",
    "                # is an outlier\n",
    "                return OUTLIER_TIMESTAMP\n",
    "            else:\n",
    "                # is not an outlier\n",
    "                return datetime\n",
    "        except ValueError:\n",
    "            # cannot parse as timestamp, it's an outlier\n",
    "            return OUTLIER_TIMESTAMP\n",
    "    df[att] = df[att].parallel_map(parse_and_check_datetime)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3b631d093f46e0837f5a2a9067c16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2302), Label(value='0 / 2302'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the filter to datetime column\n",
    "users = filter_datetime(users, 'created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Handling the statuses_count column.\n",
    "#\n",
    "status_count_median = users['statuses_count'].median()\n",
    "\n",
    "# replace the null values with median\n",
    "users['statuses_count'].fillna(status_count_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Casting all dataset\n",
    "#\n",
    "users = users.astype({\n",
    "    'id': 'int64',\n",
    "    'name': 'string',\n",
    "    'lang': 'string',\n",
    "    'bot': 'bool',\n",
    "    'statuses_count': 'int64',\n",
    "    'created_at': 'datetime64[ns]'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:14:25,527 - root - INFO - Removed 0 duplicates record that are 0.0% of dataset.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Removing duplicate records.\n",
    "#\n",
    "initial_ds_len = len(users)\n",
    "users = users.drop_duplicates()\n",
    "lg.info(f'Removed {initial_ds_len - len(users)} duplicates record that are {(initial_ds_len - len(users)) / initial_ds_len * 100}% of dataset.')\n",
    "del initial_ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11508 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   id              11508 non-null  int64         \n",
      " 1   name            11508 non-null  string        \n",
      " 2   lang            11508 non-null  string        \n",
      " 3   bot             11508 non-null  bool          \n",
      " 4   created_at      11508 non-null  datetime64[ns]\n",
      " 5   statuses_count  11508 non-null  int64         \n",
      "dtypes: bool(1), datetime64[ns](1), int64(2), string(2)\n",
      "memory usage: 550.7 KB\n"
     ]
    }
   ],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all the columns are now validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>bot</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11508</td>\n",
       "      <td>11508</td>\n",
       "      <td>11508</td>\n",
       "      <td>11508.000000</td>\n",
       "      <td>11508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11361</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sara</td>\n",
       "      <td>en</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>9973</td>\n",
       "      <td>6116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5681.686566</td>\n",
       "      <td>2017-10-03 21:23:16.013121280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012-01-24 01:57:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2017-01-18 09:50:16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2018-01-30 17:20:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2520.250000</td>\n",
       "      <td>2019-02-25 00:17:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>399555.000000</td>\n",
       "      <td>2020-04-21 07:28:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18769.594489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   lang    bot  statuses_count                     created_at\n",
       "count   11508  11508  11508    11508.000000                          11508\n",
       "unique  11361     22      2             NaN                            NaN\n",
       "top      Sara     en   True             NaN                            NaN\n",
       "freq        7   9973   6116             NaN                            NaN\n",
       "mean      NaN    NaN    NaN     5681.686566  2017-10-03 21:23:16.013121280\n",
       "min       NaN    NaN    NaN        0.000000            2012-01-24 01:57:38\n",
       "25%       NaN    NaN    NaN       42.000000     2017-01-18 09:50:16.500000\n",
       "50%       NaN    NaN    NaN       68.000000            2018-01-30 17:20:36\n",
       "75%       NaN    NaN    NaN     2520.250000            2019-02-25 00:17:30\n",
       "max       NaN    NaN    NaN   399555.000000            2020-04-21 07:28:31\n",
       "std       NaN    NaN    NaN    18769.594489                            NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Describe the pre-processed dataset with all columns.\n",
    "#\n",
    "users[['name', 'lang', 'bot', 'statuses_count', 'created_at']].describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:14:41,875 - root - INFO - Starting dataset cleaning with validators...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bcd20f11ad46c4ae6390a71f13f40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2732940), Label(value='0 / 2732940…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:19:22,760 - root - INFO - Deleted rows 950040 (0.07472007107388513%)\n"
     ]
    }
   ],
   "source": [
    "column_validators = [\n",
    "    ('id', check_positive_int),\n",
    "    ('user_id', check_positive_int),\n",
    "    ('retweet_count', check_positive_int),\n",
    "    ('reply_count', check_positive_int),\n",
    "    ('favorite_count', check_positive_int),\n",
    "    ('num_hashtags', check_positive_int),\n",
    "    ('num_urls', check_positive_int),\n",
    "    ('num_mentions', check_positive_int),\n",
    "    ('created_at', check_date),\n",
    "    ('text', check_text),\n",
    "]\n",
    "\n",
    "# clean the dataset using validators ratio function.\n",
    "lg.info(\"Starting dataset cleaning with validators...\")\n",
    "tweets, trash = clean_invalid_rows(tweets, column_validators)\n",
    "lg.info(f\"Deleted rows {trash} ({trash / len(tweets)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to remove the `id` column because it's not relevant to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Dropping id column\n",
    "#\n",
    "tweets = tweets.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze all columns\n",
    "\n",
    "The followings cells perform analysis on type and convert invalid type in an OUTLIER_VALUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:21:34,242 - root - INFO - 497404180     4600\n",
      "7004532       4580\n",
      "157029836     4578\n",
      "1693274954    4572\n",
      "491630583     4570\n",
      "              ... \n",
      "141bb            1\n",
      "r0my9w           1\n",
      "d1vl1f           1\n",
      "6zuw4z9          1\n",
      "fig6             1\n",
      "Name: user_id, Length: 116688, dtype: int64\n",
      "2022-11-02 21:21:34,959 - root - INFO - 0             9028918\n",
      "1             1123270\n",
      "2              342332\n",
      "3              172850\n",
      "4              106992\n",
      "               ...   \n",
      "qheviow             1\n",
      "dsmh                1\n",
      "ztqdk               1\n",
      "7174ogaxjr          1\n",
      "rf24duucpb          1\n",
      "Name: retweet_count, Length: 150718, dtype: int64\n",
      "2022-11-02 21:21:35,575 - root - INFO - 0             11790440\n",
      "0.0             688411\n",
      "1                15670\n",
      "2                 1454\n",
      "1.0                946\n",
      "                ...   \n",
      "nk4hbe25gv           1\n",
      "p6rhyb3zdd           1\n",
      "mdc1z1l6i            1\n",
      "aicmqt0qo            1\n",
      "otsduzr              1\n",
      "Name: reply_count, Length: 106304, dtype: int64\n",
      "2022-11-02 21:21:36,197 - root - INFO - 0             9467209\n",
      "1             1408466\n",
      "0.0            552471\n",
      "2              407252\n",
      "3              183342\n",
      "               ...   \n",
      "bf6wmj2             1\n",
      "m4vh                1\n",
      "hkyahl              1\n",
      "rvck                1\n",
      "09vtlcms9k          1\n",
      "Name: favorite_count, Length: 106590, dtype: int64\n",
      "2022-11-02 21:21:36,814 - root - INFO - 0             10470209\n",
      "1               911568\n",
      "0.0             613593\n",
      "2               270666\n",
      "3                88101\n",
      "                ...   \n",
      "q5r                  1\n",
      "gdvfamvz             1\n",
      "kvo4ljv              1\n",
      "pwrziwmqjt           1\n",
      "kmmt7p21sf           1\n",
      "Name: num_hashtags, Length: 104779, dtype: int64\n",
      "2022-11-02 21:21:37,438 - root - INFO - 0           9894198\n",
      "1           1890891\n",
      "0.0          578761\n",
      "1.0          109826\n",
      "2             23770\n",
      "             ...   \n",
      "i1eau             1\n",
      "i7qde838          1\n",
      "56lsi8cq          1\n",
      "qlsgjvc           1\n",
      "ix0n              1\n",
      "Name: num_urls, Length: 104779, dtype: int64\n",
      "2022-11-02 21:21:38,040 - root - INFO - 0          7454712\n",
      "1          4051312\n",
      "2           708611\n",
      "3           172330\n",
      "4            54824\n",
      "            ...   \n",
      "q1de             1\n",
      "p7x5v            1\n",
      "jpi2krb          1\n",
      "1zc              1\n",
      "8155oi           1\n",
      "Name: num_mentions, Length: 105627, dtype: int64\n",
      "2022-11-02 21:21:46,162 - root - INFO - 2020-04-04 03:43:02    124\n",
      "2020-04-04 03:43:01     90\n",
      "2020-04-04 05:01:46     78\n",
      "2020-04-04 05:01:47     68\n",
      "2020-04-04 03:23:46     48\n",
      "                      ... \n",
      "2019-06-18 16:39:19      1\n",
      "2020-03-25 19:41:31      1\n",
      "2020-02-15 19:23:23      1\n",
      "2019-07-09 17:08:07      1\n",
      "2019-07-10 12:00:00      1\n",
      "Name: created_at, Length: 8127084, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Examine the columns domain.\n",
    "#\n",
    "for col in tweets.columns:\n",
    "    if col == 'text':\n",
    "        #\n",
    "        # skip the text column\n",
    "        #\n",
    "        continue\n",
    "    lg.info(tweets[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have a lot of invalid values, hence we need to replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function that replaces invalid values with an outlier value\n",
    "def replace_with_outlier(dataset, col_name, check_function, outlier_value):\n",
    "    df = dataset.copy()\n",
    "    v = df[col_name].parallel_map(check_function)\n",
    "    record_touched = len(v) - sum(v)\n",
    "    \n",
    "    df.loc[v == False, col_name] = df[v == False][col_name].apply(lambda x: outlier_value)\n",
    "    return df, record_touched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check function for integer values\n",
    "def check_integer_column(x):\n",
    "    try:\n",
    "        # we try to cast to int\n",
    "        int(str(x))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all columns to be checked\n",
    "INTEGER_COLUMNS = [\n",
    "    'user_id',\n",
    "    'retweet_count',\n",
    "    'reply_count',\n",
    "    'favorite_count',\n",
    "    'num_hashtags',\n",
    "    'num_urls',\n",
    "    'num_mentions',\n",
    "]\n",
    "\n",
    "# outlier value\n",
    "OUTLIER_VALUE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793aab09a1064693826f612d8a8afcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:21:53,746 - root - INFO - Detected 213943 user_id with invalid value, i.e. 1.682648748027473% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b672f62e45a44c6f8d644db2e0ec881f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:21:59,384 - root - INFO - Detected 213878 retweet_count with invalid value, i.e. 1.6821375269610126% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab24ccf20ac44fb865fb85b2a5840fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:06,092 - root - INFO - Detected 904055 reply_count with invalid value, i.e. 7.11033786521633% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4011d3fbcfe4f998376a1ac7b202138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:12,689 - root - INFO - Detected 904073 favorite_count with invalid value, i.e. 7.110479434127042% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b52a2f2bf2d4f19a17730816a126d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:19,336 - root - INFO - Detected 904090 num_hashtags with invalid value, i.e. 7.1106131380982704% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3476a4304fde4851b7d097f9007f3be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:26,052 - root - INFO - Detected 904070 num_urls with invalid value, i.e. 7.11045583930859% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdfeca52ed14d189f22bf009b30946e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:31,962 - root - INFO - Detected 214130 num_mentions with invalid value, i.e. 1.684119491710983% of dataset\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Replace invalid integer columns\n",
    "#\n",
    "for col in INTEGER_COLUMNS:\n",
    "    tweets, removed = replace_with_outlier(\n",
    "        tweets,\n",
    "        col,\n",
    "        check_integer_column,\n",
    "        OUTLIER_VALUE,\n",
    "    )\n",
    "    lg.info(f\"Detected {removed} {col} with invalid value, i.e. {removed / len(tweets) * 100}% of dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical columns, replace with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a simple function that replaces missing values with the median (only numerical)\n",
    "def clean_with_median(dataset, col_name):\n",
    "    df = dataset.copy()\n",
    "    v = df[col_name].parallel_map(lambda x: x != OUTLIER_VALUE)\n",
    "    median = df[v == True][col_name].median()\n",
    "    df.loc[v == False, col_name] = df[v == False][col_name].apply(lambda x: median)\n",
    "    \n",
    "    return df, sum(~v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662a1794751145cd9b99956c3c0214ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:41,634 - root - INFO - Detected 213943 rows with outlier value i.e. 1.682648748027473% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d621bb5a3b499f8ac239d86b2f2496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:50,263 - root - INFO - Detected 213878 rows with outlier value i.e. 1.6821375269610126% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14acf90c17ad4e22a47f66088eb24beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:22:58,868 - root - INFO - Detected 904055 rows with outlier value i.e. 7.11033786521633% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a18137f86444bd3bdf0584b8e9d0598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:23:07,601 - root - INFO - Detected 904073 rows with outlier value i.e. 7.110479434127042% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf94f9d434cc42ab9ec5e9081e71556e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:23:16,350 - root - INFO - Detected 904090 rows with outlier value i.e. 7.1106131380982704% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737a59388b354e898fe0d977d06dfb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:23:25,145 - root - INFO - Detected 904070 rows with outlier value i.e. 7.11045583930859% of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1adf8c51bd1412090b3267c3bb70e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:23:33,936 - root - INFO - Detected 214130 rows with outlier value i.e. 1.684119491710983% of dataset\n"
     ]
    }
   ],
   "source": [
    "# Replacing missing data with median\n",
    "for col in INTEGER_COLUMNS:\n",
    "    tweets, affected = clean_with_median(tweets, col)\n",
    "    lg.info(f'Detected {affected} rows with outlier value i.e. {affected / len(tweets) * 100}% of dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing the text column, we want to make the column a string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bed25779e4d4051afc3b06b2442ba2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-02 21:23:44,250 - root - INFO - Found 49420 records, i.e. 0.3886853092997561% of dataset\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Compute statistics\n",
    "#\n",
    "invalid_texts = tweets['text'].parallel_map(pd.isnull)\n",
    "lg.info(f\"Found {sum(invalid_texts)} records, i.e. {sum(invalid_texts) / len(invalid_texts) * 100}% of dataset\")\n",
    "# to optize the memory\n",
    "del invalid_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the text record\n",
    "def handle_text_record(x):\n",
    "    if pd.isnull(x):\n",
    "        return ''\n",
    "    else:\n",
    "        x = str(x).strip()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab3a9303d4749ae91c86e435dd146cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute the function\n",
    "tweets['text'] = tweets['text'].parallel_map(handle_text_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pandarallel/data_types/series.py:42: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield data[chunk_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f8d952d4a9419db87512ea78a26f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2542932), Label(value='0 / 2542932…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Managing the Datetime column\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [16], line 19\u001b[0m, in \u001b[0;36mfilter_datetime\u001b[0;34m(df, att)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# cannot parse as timestamp, it's an outlier\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m OUTLIER_TIMESTAMP\n\u001b[0;32m---> 19\u001b[0m df[att] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43matt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_and_check_datetime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandarallel/core.py:307\u001b[0m, in \u001b[0;36mparallelize_with_memory_file_system.<locals>.closure\u001b[0;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m generation \u001b[38;5;241m=\u001b[39m count()\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    302\u001b[0m     (\n\u001b[1;32m    303\u001b[0m         worker_status \u001b[38;5;241m==\u001b[39m WorkerStatus\u001b[38;5;241m.\u001b[39mRunning\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m worker_status \u001b[38;5;129;01min\u001b[39;00m workers_status\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m ):\n\u001b[0;32m--> 307\u001b[0m     message: Tuple[\u001b[38;5;28mint\u001b[39m, WorkerStatus, Any] \u001b[38;5;241m=\u001b[39m \u001b[43mmaster_workers_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     worker_index, worker_status, payload \u001b[38;5;241m=\u001b[39m message\n\u001b[1;32m    309\u001b[0m     workers_status[worker_index] \u001b[38;5;241m=\u001b[39m worker_status\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/managers.py:818\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    815\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tls\u001b[38;5;241m.\u001b[39mconnection\n\u001b[1;32m    817\u001b[0m conn\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id, methodname, args, kwds))\n\u001b[0;32m--> 818\u001b[0m kind, result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#RETURN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:255\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 255\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Managing the Datetime column\n",
    "#\n",
    "tweets = filter_datetime(tweets, 'created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Casting all dataset\n",
    "#\n",
    "tweets = tweets.astype({\n",
    "    'user_id': 'int64',\n",
    "    'retweet_count': 'int64',\n",
    "    'reply_count': 'int64',\n",
    "    'favorite_count': 'int64',\n",
    "    'num_hashtags': 'int64',\n",
    "    'num_urls': 'int64',\n",
    "    'num_mentions': 'int64',\n",
    "    'created_at': 'datetime64[ns]',\n",
    "    'text': 'string',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Printing statistics about cleaning\n",
    "#\n",
    "\n",
    "initial_ds_len = len(tweets)\n",
    "tweets = tweets.drop_duplicates()\n",
    "lg.info(f'Removed {initial_ds_len - len(tweets)} duplicates record that are {(initial_ds_len - len(tweets)) / initial_ds_len * 100}% of dataset.')\n",
    "del initial_ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Describe the pre-processed dataset with all columns.\n",
    "#\n",
    "tweets[['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions', 'created_at']].describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution analysis\n",
    "\n",
    "In the following cell we plot statistics acoording to cleaned data to detect outliers and handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Load the CSV\n",
    "#\n",
    "#users = pd.read_csv('cleaned_dataset/users_cleaned.csv')\n",
    "#tweets = pd.read_csv('cleaned_dataset/tweets_cleaned.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from utils import build_grid_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['statuses_count'],\n",
    "        'title': 'Statues Counts',\n",
    "        'yscale': 'log',\n",
    "    },\n",
    "    {\n",
    "        'type': 'bar',\n",
    "        'column': users['bot'].map(lambda v: 'Bot' if v else 'User'),\n",
    "        'title': 'Bot and User Counts',\n",
    "        'rotation': True,\n",
    "    },\n",
    "    {\n",
    "        'type': 'bar',\n",
    "        'column': users['lang'],\n",
    "        'title': 'Languages Counts',\n",
    "        'yscale': 'log',\n",
    "    },\n",
    "    {\n",
    "        'type': 'hist',\n",
    "        'column': users['created_at'][users['created_at'] > pd.Timestamp(OUTLIER_TIMESTAMP)],\n",
    "        'title': 'User Creation Date Distribution',\n",
    "        'yscale': 'log',\n",
    "    }\n",
    "]\n",
    "\n",
    "build_grid_plot(configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_hist_tweets():\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'hist',\n",
    "            'column': tweets['retweet_count'],\n",
    "            'title': 'Retweet Counts',\n",
    "        },\n",
    "        {\n",
    "            'type': 'hist',\n",
    "            'column': tweets['reply_count'],\n",
    "            'title': 'Replay Counts',\n",
    "            'yscale': 'log',\n",
    "        },\n",
    "        {\n",
    "            'type': 'hist',\n",
    "            'column': tweets['favorite_count'],\n",
    "            'title': 'Favorite Counts',\n",
    "            'yscale': 'log',\n",
    "        },\n",
    "        {\n",
    "            'type': 'hist',\n",
    "            'column': tweets['num_hashtags'],\n",
    "            'title': 'Hashtag Counts',\n",
    "            'yscale': 'log',\n",
    "        },\n",
    "        {\n",
    "            'type': 'hist',\n",
    "            'column': tweets['num_urls'],\n",
    "            'title': 'Url Counts',\n",
    "            'yscale': 'log',\n",
    "        },\n",
    "        {\n",
    "            'type': 'hist',\n",
    "            'column': tweets['num_mentions'],\n",
    "            'title': 'Mentions Counts',\n",
    "            'yscale': 'log',\n",
    "        },\n",
    "        {\n",
    "            'type': 'hist',\n",
    "            'column': tweets['created_at'][tweets['created_at'] > pd.Timestamp(OUTLIER_TIMESTAMP)],\n",
    "            'title': 'Tweets Creation Date Distribution',\n",
    "            'yscale': 'log',\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)\n",
    "\n",
    "plot_hist_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all numerical columns there are outliers to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def boxplot_tweets_show(yscale='linear'):\n",
    "    configs = [\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['retweet_count'],\n",
    "            'yscale': yscale,\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['reply_count'],\n",
    "            'yscale': yscale,\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['favorite_count'],\n",
    "            'yscale': yscale,\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_hashtags'],\n",
    "            'yscale': yscale,\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_urls'],\n",
    "            'yscale': yscale,\n",
    "        },\n",
    "        {\n",
    "            'type': 'boxplot',\n",
    "            'df': tweets,\n",
    "            'columns': ['num_mentions'],\n",
    "            'yscale': yscale,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    build_grid_plot(configs=configs)\n",
    "\n",
    "boxplot_tweets_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_outliers(df, column_name, threshold):\n",
    "    column = df[column_name]\n",
    "    to_replace = len(column[column > threshold])\n",
    "    perc_to_replace = to_replace / len(column) * 100\n",
    "    lg.info(f'{to_replace} ({perc_to_replace}%) element replaced for column {column_name}')\n",
    "    median = column.median()\n",
    "    df[column_name] = column.parallel_map(lambda x: median if x > threshold else x)\n",
    "\n",
    "replace_outliers(tweets, 'retweet_count', 6e5)\n",
    "replace_outliers(tweets, 'reply_count', 6e4)\n",
    "replace_outliers(tweets, 'favorite_count', 1.2e5)\n",
    "replace_outliers(tweets, 'num_hashtags', 1e4)\n",
    "replace_outliers(tweets, 'num_urls', 1e4)\n",
    "replace_outliers(tweets, 'num_mentions', 1e5)\n",
    "\n",
    "boxplot_tweets_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_num_cols = ['statuses_count', 'bot']\n",
    "users.astype({'bot': 'int64'}).corr(method='pearson', numeric_only=True).loc[users_num_cols, users_num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_num_cols = ['user_id', 'retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions']\n",
    "tweets.corr(method='pearson', numeric_only=True).loc[tweets_num_cols, tweets_num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "tweets.plot.scatter(x='reply_count', y='favorite_count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "cat_tweets = users.drop(columns=tweets_num_cols)\n",
    "\n",
    "X_pca = PCA(n_components=2).fit_transform(cat_tweets)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "plt.title(\"PCA\")\n",
    "plt.xlabel(\"1st eigenvector\")\n",
    "plt.ylabel(\"2nd eigenvector\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> TODO prof recap points for DATA UNDERSTANDING\n",
    "(last slide of data understanding)\n",
    "Checklist for Data Understanding\n",
    "- Determine the quality of the data.(e.g.syntactic accuracy)\n",
    "- Find outliers. (e. g. using visualization techniques)\n",
    "- Detect and examine missing values. Possible hidden by default values.\n",
    "- Discover new or confirm expected dependencies or correlations between attributes.\n",
    "- Check specific application dependent assumptions (e.g. the attribute follows a normal distribution)\n",
    "- Compare statistics with the expected behaviour.\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
